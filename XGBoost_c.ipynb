{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import TimeSeriesSplit \n",
    "import optuna\n",
    "import json\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "#Load inn datasets\n",
    "X_test  = pd.read_parquet('data/prepared_datasets/avg/no_duplicates/X_test.parquet')\n",
    "X_train = pd.read_parquet('data/prepared_datasets/avg/no_duplicates/X_train.parquet')\n",
    "y_train = pd.read_parquet('data/prepared_datasets/avg/no_duplicates/Y_train.parquet')\n",
    "y_train_a = pd.read_parquet('data/prepared_datasets/avg/no_duplicates/Y_train_a.parquet')\n",
    "y_train_b = pd.read_parquet('data/prepared_datasets/avg/no_duplicates/Y_train_b.parquet')\n",
    "y_train_c = pd.read_parquet('data/prepared_datasets/avg/no_duplicates/Y_train_c.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import optuna\n",
    "\n",
    "def test_train_split(df):\n",
    "    dates_2 = (df.index >= '2023-04-01') & (df.index <= '2023-04-15')\n",
    "    dates_1 = (df.index >= '2021-05-01') & (df.index <= '2021-08-01')\n",
    "\n",
    "    test_set = df[dates_1 | dates_2]\n",
    "\n",
    "    training_set = df[~(dates_1 | dates_2)]\n",
    "\n",
    "    X_train = training_set.drop(\"pv_measurement\", axis=1)\n",
    "    y_train = training_set['pv_measurement']\n",
    "\n",
    "    X_test = test_set.drop(\"pv_measurement\", axis=1)\n",
    "    y_test = test_set['pv_measurement'] \n",
    "\n",
    "    \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_trainnew_a, X_test_new_a, y_train_new_a, y_test_a = test_train_split(pd.concat([X_train[X_train[\"location\"] == \"A\"].drop(\"location\", axis=1), y_train_a], axis=1))\n",
    "X_train_new_b, X_test_new_b, y_train_new_b, y_test_b = test_train_split(pd.concat([X_train[X_train[\"location\"] == \"B\"].drop(\"location\", axis=1), y_train_b], axis=1))\n",
    "X_train_new_c, X_test_new_c, y_train_new_c, y_test_c = test_train_split(pd.concat([X_train[X_train[\"location\"] == \"C\"].drop(\"location\", axis=1), y_train_c], axis=1))\n",
    "\n",
    "X_train_loc_a, X_test_loc_a, y_train_loc_a, y_test_a = test_train_split(pd.concat([X_train[X_train[\"location\"] == \"A\"], y_train_a], axis=1))\n",
    "X_train_loc_b, X_test_loc_b, y_train_loc_b, y_test_b = test_train_split(pd.concat([X_train[X_train[\"location\"] == \"B\"], y_train_b], axis=1))\n",
    "X_train_loc_c, X_test_loc_c, y_train_loc_c, y_test_c = test_train_split(pd.concat([X_train[X_train[\"location\"] == \"C\"], y_train_c], axis=1))\n",
    "\n",
    "\n",
    "X_train_new = pd.concat([X_train_loc_a, X_train_loc_b, X_train_loc_c])\n",
    "X_test_new = pd.concat([X_test_loc_a, X_test_loc_b, X_test_loc_c])\n",
    "y_train_new = pd.concat([y_train_loc_a, y_train_loc_b, y_train_loc_c])\n",
    "y_test = pd.concat([y_test_a, y_test_b, y_test_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-11 17:48:21,590] A new study created in memory with name: no-name-ed7c4780-75f4-4f2b-ba25-50afec9b5fb1\n",
      "[I 2023-11-11 17:48:27,493] Trial 0 finished with value: 54.051558622714424 and parameters: {'n_estimators': 2205, 'learning_rate': 0.00861681614148598, 'max_depth': 7, 'subsample': 0.23165537499254718, 'colsample_bytree': 0.6205674755158046, 'min_child_weight': 5}. Best is trial 0 with value: 54.051558622714424.\n",
      "[I 2023-11-11 17:48:34,421] Trial 1 finished with value: 58.105648068040736 and parameters: {'n_estimators': 1390, 'learning_rate': 0.001396180272494732, 'max_depth': 7, 'subsample': 0.8253114972245926, 'colsample_bytree': 0.9610189540415709, 'min_child_weight': 5}. Best is trial 0 with value: 54.051558622714424.\n",
      "[I 2023-11-11 17:48:44,767] Trial 2 finished with value: 54.4916107213996 and parameters: {'n_estimators': 2813, 'learning_rate': 0.0407863909937016, 'max_depth': 9, 'subsample': 0.825747780910301, 'colsample_bytree': 0.3481421842634262, 'min_child_weight': 19}. Best is trial 0 with value: 54.051558622714424.\n",
      "[I 2023-11-11 17:48:47,212] Trial 3 finished with value: 55.45636764027422 and parameters: {'n_estimators': 1024, 'learning_rate': 0.02919929976193577, 'max_depth': 6, 'subsample': 0.2078154074529791, 'colsample_bytree': 0.6924439658698016, 'min_child_weight': 5}. Best is trial 0 with value: 54.051558622714424.\n",
      "[I 2023-11-11 17:48:48,783] Trial 4 finished with value: 58.75688581036075 and parameters: {'n_estimators': 1858, 'learning_rate': 0.007736385712582435, 'max_depth': 1, 'subsample': 0.29444415271417246, 'colsample_bytree': 0.2628266924772075, 'min_child_weight': 17}. Best is trial 0 with value: 54.051558622714424.\n",
      "[I 2023-11-11 17:48:54,509] Trial 5 finished with value: 53.72640538016738 and parameters: {'n_estimators': 2668, 'learning_rate': 0.001127141717144951, 'max_depth': 6, 'subsample': 0.23367684580762837, 'colsample_bytree': 0.2629292652782788, 'min_child_weight': 12}. Best is trial 5 with value: 53.72640538016738.\n",
      "[I 2023-11-11 17:48:56,122] Trial 6 finished with value: 55.7264379015272 and parameters: {'n_estimators': 1319, 'learning_rate': 0.033048035757460695, 'max_depth': 2, 'subsample': 0.5072756018156824, 'colsample_bytree': 0.8572037005555149, 'min_child_weight': 10}. Best is trial 5 with value: 53.72640538016738.\n",
      "[I 2023-11-11 17:48:58,824] Trial 7 finished with value: 76.8142395467526 and parameters: {'n_estimators': 2760, 'learning_rate': 0.0010029912916822855, 'max_depth': 1, 'subsample': 0.7377141207320732, 'colsample_bytree': 0.19792862586665738, 'min_child_weight': 5}. Best is trial 5 with value: 53.72640538016738.\n",
      "[I 2023-11-11 17:49:09,719] Trial 8 finished with value: 53.044442092272845 and parameters: {'n_estimators': 2022, 'learning_rate': 0.004985603417050592, 'max_depth': 9, 'subsample': 0.9637150868953115, 'colsample_bytree': 0.9438003033381516, 'min_child_weight': 20}. Best is trial 8 with value: 53.044442092272845.\n",
      "[I 2023-11-11 17:49:11,473] Trial 9 finished with value: 54.82203865366639 and parameters: {'n_estimators': 1280, 'learning_rate': 0.025779704084934373, 'max_depth': 3, 'subsample': 0.5763381386270335, 'colsample_bytree': 0.6198884316179316, 'min_child_weight': 18}. Best is trial 8 with value: 53.044442092272845.\n",
      "[I 2023-11-11 17:49:24,111] Trial 10 finished with value: 54.4515442840008 and parameters: {'n_estimators': 1989, 'learning_rate': 0.09470392389447377, 'max_depth': 10, 'subsample': 0.9697813874310448, 'colsample_bytree': 0.8302885701034817, 'min_child_weight': 14}. Best is trial 8 with value: 53.044442092272845.\n",
      "[I 2023-11-11 17:49:27,740] Trial 11 finished with value: 59.947128018502035 and parameters: {'n_estimators': 2432, 'learning_rate': 0.003243259144800257, 'max_depth': 4, 'subsample': 0.10961033250182309, 'colsample_bytree': 0.07264084306159044, 'min_child_weight': 11}. Best is trial 8 with value: 53.044442092272845.\n",
      "[I 2023-11-11 17:49:36,368] Trial 12 finished with value: 52.37190964846507 and parameters: {'n_estimators': 2472, 'learning_rate': 0.0032240449885997708, 'max_depth': 8, 'subsample': 0.41934954660478707, 'colsample_bytree': 0.4337937551472138, 'min_child_weight': 14}. Best is trial 12 with value: 52.37190964846507.\n",
      "[I 2023-11-11 17:49:43,535] Trial 13 finished with value: 52.635417992067424 and parameters: {'n_estimators': 1743, 'learning_rate': 0.004465504546890098, 'max_depth': 9, 'subsample': 0.43244949560538526, 'colsample_bytree': 0.4587938281804625, 'min_child_weight': 16}. Best is trial 12 with value: 52.37190964846507.\n",
      "[I 2023-11-11 17:49:50,403] Trial 14 finished with value: 51.4542679265907 and parameters: {'n_estimators': 1677, 'learning_rate': 0.0025477862772143563, 'max_depth': 8, 'subsample': 0.4081423014883566, 'colsample_bytree': 0.448811450626527, 'min_child_weight': 15}. Best is trial 14 with value: 51.4542679265907.\n",
      "[I 2023-11-11 17:50:00,384] Trial 15 finished with value: 51.68731707317049 and parameters: {'n_estimators': 2404, 'learning_rate': 0.002339617765284505, 'max_depth': 8, 'subsample': 0.36474919283130613, 'colsample_bytree': 0.43047223909123095, 'min_child_weight': 9}. Best is trial 14 with value: 51.4542679265907.\n",
      "[I 2023-11-11 17:50:03,436] Trial 16 finished with value: 52.91305500056364 and parameters: {'n_estimators': 1651, 'learning_rate': 0.0019982074644170427, 'max_depth': 5, 'subsample': 0.051955841273076564, 'colsample_bytree': 0.5269743646872704, 'min_child_weight': 8}. Best is trial 14 with value: 51.4542679265907.\n",
      "[I 2023-11-11 17:50:15,768] Trial 17 finished with value: 50.901244181077125 and parameters: {'n_estimators': 2250, 'learning_rate': 0.0019268028173209794, 'max_depth': 8, 'subsample': 0.36254140280169894, 'colsample_bytree': 0.4281621252243835, 'min_child_weight': 2}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 17:50:46,153] Trial 18 finished with value: 50.98594618203223 and parameters: {'n_estimators': 2139, 'learning_rate': 0.0017289354271823266, 'max_depth': 10, 'subsample': 0.5625865009289909, 'colsample_bytree': 0.35875115331680363, 'min_child_weight': 1}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 17:51:18,038] Trial 19 finished with value: 50.97800284148575 and parameters: {'n_estimators': 2107, 'learning_rate': 0.0018037379977832132, 'max_depth': 10, 'subsample': 0.6300229492130677, 'colsample_bytree': 0.33579622795868436, 'min_child_weight': 1}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 17:51:52,951] Trial 20 finished with value: 56.820181743321285 and parameters: {'n_estimators': 2984, 'learning_rate': 0.001753105300851575, 'max_depth': 10, 'subsample': 0.5988660321123652, 'colsample_bytree': 0.12111046234702691, 'min_child_weight': 1}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 17:52:25,504] Trial 21 finished with value: 51.182978013393374 and parameters: {'n_estimators': 2212, 'learning_rate': 0.001598849184520278, 'max_depth': 10, 'subsample': 0.640241679474166, 'colsample_bytree': 0.33157999104340596, 'min_child_weight': 1}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 17:52:48,938] Trial 22 finished with value: 51.771344281670075 and parameters: {'n_estimators': 2198, 'learning_rate': 0.001413924099934537, 'max_depth': 10, 'subsample': 0.5074447074519973, 'colsample_bytree': 0.34926955457740555, 'min_child_weight': 3}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 17:53:09,376] Trial 23 finished with value: 60.92375978552257 and parameters: {'n_estimators': 2058, 'learning_rate': 0.0010239561546356991, 'max_depth': 9, 'subsample': 0.6438603824676115, 'colsample_bytree': 0.2043766481687892, 'min_child_weight': 3}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 17:53:22,991] Trial 24 finished with value: 51.160171399086316 and parameters: {'n_estimators': 2304, 'learning_rate': 0.0020672962505433705, 'max_depth': 7, 'subsample': 0.5419770276289659, 'colsample_bytree': 0.357946775210838, 'min_child_weight': 2}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 17:53:39,239] Trial 25 finished with value: 52.41461425770557 and parameters: {'n_estimators': 2566, 'learning_rate': 0.003801362205927253, 'max_depth': 8, 'subsample': 0.5052476924722651, 'colsample_bytree': 0.5112655249646653, 'min_child_weight': 7}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 17:54:01,477] Trial 26 finished with value: 51.70103170369363 and parameters: {'n_estimators': 1854, 'learning_rate': 0.00574675623843699, 'max_depth': 10, 'subsample': 0.6780249055582348, 'colsample_bytree': 0.2808901105291409, 'min_child_weight': 3}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 17:54:19,424] Trial 27 finished with value: 52.35350309280807 and parameters: {'n_estimators': 2104, 'learning_rate': 0.0033071318296317167, 'max_depth': 9, 'subsample': 0.4574021344194069, 'colsample_bytree': 0.17538531653952572, 'min_child_weight': 1}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 17:54:31,339] Trial 28 finished with value: 51.38621376510684 and parameters: {'n_estimators': 1936, 'learning_rate': 0.0024000460049238477, 'max_depth': 9, 'subsample': 0.3343051235542603, 'colsample_bytree': 0.37629998369954437, 'min_child_weight': 7}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 17:54:39,971] Trial 29 finished with value: 52.95581801974179 and parameters: {'n_estimators': 2305, 'learning_rate': 0.007286145080981858, 'max_depth': 7, 'subsample': 0.5622411751208217, 'colsample_bytree': 0.5308005998287628, 'min_child_weight': 6}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 17:54:43,267] Trial 30 finished with value: 53.63980531002582 and parameters: {'n_estimators': 1531, 'learning_rate': 0.011928190054485784, 'max_depth': 5, 'subsample': 0.4816858830526805, 'colsample_bytree': 0.28999594625262126, 'min_child_weight': 3}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 17:54:52,886] Trial 31 finished with value: 51.157270911420696 and parameters: {'n_estimators': 2273, 'learning_rate': 0.001861862563174938, 'max_depth': 7, 'subsample': 0.5820727800989489, 'colsample_bytree': 0.3536713090374401, 'min_child_weight': 2}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 17:55:02,580] Trial 32 finished with value: 51.50543529083106 and parameters: {'n_estimators': 2170, 'learning_rate': 0.001494859618630398, 'max_depth': 7, 'subsample': 0.5768227524447969, 'colsample_bytree': 0.39610152565120416, 'min_child_weight': 4}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 17:55:18,216] Trial 33 finished with value: 51.566096762625705 and parameters: {'n_estimators': 2289, 'learning_rate': 0.0014230423221129214, 'max_depth': 8, 'subsample': 0.7469464935562163, 'colsample_bytree': 0.3133922830795103, 'min_child_weight': 2}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 17:55:24,769] Trial 34 finished with value: 51.780648704652876 and parameters: {'n_estimators': 2471, 'learning_rate': 0.0026927175448539396, 'max_depth': 6, 'subsample': 0.46982936060896696, 'colsample_bytree': 0.39345390662059915, 'min_child_weight': 4}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 17:55:31,400] Trial 35 finished with value: 52.66748560331978 and parameters: {'n_estimators': 1832, 'learning_rate': 0.001802484032971791, 'max_depth': 7, 'subsample': 0.37621461860762295, 'colsample_bytree': 0.23315123815881006, 'min_child_weight': 2}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 17:55:52,602] Trial 36 finished with value: 52.406737381241406 and parameters: {'n_estimators': 2558, 'learning_rate': 0.0011715848394046303, 'max_depth': 9, 'subsample': 0.6051382678802942, 'colsample_bytree': 0.30827020010531075, 'min_child_weight': 4}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 17:55:58,200] Trial 37 finished with value: 51.69513916844667 and parameters: {'n_estimators': 2136, 'learning_rate': 0.001928393703462459, 'max_depth': 6, 'subsample': 0.5310371610803832, 'colsample_bytree': 0.24938402563684264, 'min_child_weight': 6}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 17:56:11,465] Trial 38 finished with value: 52.24275391676065 and parameters: {'n_estimators': 2323, 'learning_rate': 0.0012701956282077376, 'max_depth': 8, 'subsample': 0.2940413159910742, 'colsample_bytree': 0.3256130013308662, 'min_child_weight': 1}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 17:56:36,269] Trial 39 finished with value: 51.52624269558982 and parameters: {'n_estimators': 2635, 'learning_rate': 0.002770357720467053, 'max_depth': 10, 'subsample': 0.7266436623927466, 'colsample_bytree': 0.47656335944305256, 'min_child_weight': 5}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 17:56:55,215] Trial 40 finished with value: 53.18309371781181 and parameters: {'n_estimators': 1986, 'learning_rate': 0.0012821029133849437, 'max_depth': 9, 'subsample': 0.5424364534163656, 'colsample_bytree': 0.3907401942678592, 'min_child_weight': 2}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 17:57:04,104] Trial 41 finished with value: 51.16999006810948 and parameters: {'n_estimators': 2276, 'learning_rate': 0.0021283594028224584, 'max_depth': 7, 'subsample': 0.5454566910366264, 'colsample_bytree': 0.3632476131083847, 'min_child_weight': 2}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 17:57:10,690] Trial 42 finished with value: 51.439870649323 and parameters: {'n_estimators': 2391, 'learning_rate': 0.0017055197738597224, 'max_depth': 6, 'subsample': 0.6143737227702695, 'colsample_bytree': 0.2736659807670139, 'min_child_weight': 1}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 17:57:15,023] Trial 43 finished with value: 51.558374433311556 and parameters: {'n_estimators': 2090, 'learning_rate': 0.0020254300027720694, 'max_depth': 5, 'subsample': 0.6793429110531362, 'colsample_bytree': 0.3464489513026995, 'min_child_weight': 4}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 17:57:23,043] Trial 44 finished with value: 55.64493681049872 and parameters: {'n_estimators': 1925, 'learning_rate': 0.0011310615686721134, 'max_depth': 7, 'subsample': 0.5024156975951256, 'colsample_bytree': 0.4145938069308145, 'min_child_weight': 2}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 17:57:34,035] Trial 45 finished with value: 51.824577223539016 and parameters: {'n_estimators': 2226, 'learning_rate': 0.0028607252887319157, 'max_depth': 8, 'subsample': 0.45427270467634484, 'colsample_bytree': 0.4913946677046943, 'min_child_weight': 5}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 17:57:38,588] Trial 46 finished with value: 52.82744800774935 and parameters: {'n_estimators': 2711, 'learning_rate': 0.004126949660108503, 'max_depth': 4, 'subsample': 0.5589871061602234, 'colsample_bytree': 0.3640190659392851, 'min_child_weight': 3}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 17:57:50,077] Trial 47 finished with value: 51.65308166059667 and parameters: {'n_estimators': 2837, 'learning_rate': 0.0022988429861905205, 'max_depth': 7, 'subsample': 0.5241394311489211, 'colsample_bytree': 0.5632593249346961, 'min_child_weight': 1}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 17:58:00,391] Trial 48 finished with value: 51.46383991430616 and parameters: {'n_estimators': 2354, 'learning_rate': 0.0016893951857937454, 'max_depth': 8, 'subsample': 0.4184211516742418, 'colsample_bytree': 0.4341950981761735, 'min_child_weight': 12}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 17:58:07,495] Trial 49 finished with value: 51.389106741432876 and parameters: {'n_estimators': 2517, 'learning_rate': 0.001408679291140035, 'max_depth': 6, 'subsample': 0.5869870970682108, 'colsample_bytree': 0.46384355510756, 'min_child_weight': 6}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 17:58:32,501] Trial 50 finished with value: 58.22663592387258 and parameters: {'n_estimators': 2025, 'learning_rate': 0.0010103466343231806, 'max_depth': 10, 'subsample': 0.6227308462974555, 'colsample_bytree': 0.30726903307599623, 'min_child_weight': 2}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 17:58:41,915] Trial 51 finished with value: 51.16055138874176 and parameters: {'n_estimators': 2258, 'learning_rate': 0.0020716246825769158, 'max_depth': 7, 'subsample': 0.5505829612602011, 'colsample_bytree': 0.3595313935700206, 'min_child_weight': 2}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 17:58:47,865] Trial 52 finished with value: 51.179311632695196 and parameters: {'n_estimators': 2139, 'learning_rate': 0.00211808366578116, 'max_depth': 6, 'subsample': 0.4919589064390448, 'colsample_bytree': 0.41060603300104925, 'min_child_weight': 3}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 17:58:58,495] Trial 53 finished with value: 51.33107318549483 and parameters: {'n_estimators': 1070, 'learning_rate': 0.0031716897681075317, 'max_depth': 9, 'subsample': 0.5657167648047002, 'colsample_bytree': 0.33636195911347416, 'min_child_weight': 1}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 17:59:07,411] Trial 54 finished with value: 51.37907695598895 and parameters: {'n_estimators': 2248, 'learning_rate': 0.0015505623363049846, 'max_depth': 7, 'subsample': 0.444124985354847, 'colsample_bytree': 0.426688821462564, 'min_child_weight': 4}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 17:59:10,231] Trial 55 finished with value: 53.834756796952085 and parameters: {'n_estimators': 2375, 'learning_rate': 0.002412887208075948, 'max_depth': 2, 'subsample': 0.6466828347670286, 'colsample_bytree': 0.3735979124711769, 'min_child_weight': 2}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 17:59:20,236] Trial 56 finished with value: 53.00541835154873 and parameters: {'n_estimators': 1762, 'learning_rate': 0.00178706428374104, 'max_depth': 8, 'subsample': 0.5256550535441447, 'colsample_bytree': 0.22409358738978752, 'min_child_weight': 3}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 17:59:40,168] Trial 57 finished with value: 51.33413019328362 and parameters: {'n_estimators': 2437, 'learning_rate': 0.003427000127548529, 'max_depth': 9, 'subsample': 0.4857526444721394, 'colsample_bytree': 0.25206429424252225, 'min_child_weight': 1}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 17:59:56,739] Trial 58 finished with value: 55.296245777320415 and parameters: {'n_estimators': 1953, 'learning_rate': 0.0012668540827092067, 'max_depth': 10, 'subsample': 0.5801429296273022, 'colsample_bytree': 0.2802946483323951, 'min_child_weight': 10}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 18:00:02,591] Trial 59 finished with value: 51.86981454744807 and parameters: {'n_estimators': 2194, 'learning_rate': 0.0028038982363220426, 'max_depth': 6, 'subsample': 0.4209321984563994, 'colsample_bytree': 0.45298536810115425, 'min_child_weight': 5}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 18:00:11,564] Trial 60 finished with value: 51.408989149488434 and parameters: {'n_estimators': 2048, 'learning_rate': 0.0020112855657285662, 'max_depth': 8, 'subsample': 0.6683356079465471, 'colsample_bytree': 0.3455245995044586, 'min_child_weight': 19}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 18:00:20,888] Trial 61 finished with value: 51.14715268067384 and parameters: {'n_estimators': 2271, 'learning_rate': 0.0022175809274035114, 'max_depth': 7, 'subsample': 0.5425560029931414, 'colsample_bytree': 0.3690735201782908, 'min_child_weight': 2}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 18:00:29,821] Trial 62 finished with value: 51.37434304552082 and parameters: {'n_estimators': 2261, 'learning_rate': 0.0024331069846524485, 'max_depth': 7, 'subsample': 0.6064112831133316, 'colsample_bytree': 0.394171124362096, 'min_child_weight': 2}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 18:00:38,360] Trial 63 finished with value: 51.660477052596455 and parameters: {'n_estimators': 2119, 'learning_rate': 0.0016315671209336132, 'max_depth': 7, 'subsample': 0.537546701247925, 'colsample_bytree': 0.3059622617180204, 'min_child_weight': 3}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 18:00:48,841] Trial 64 finished with value: 51.11872132808304 and parameters: {'n_estimators': 2343, 'learning_rate': 0.0022031569583649854, 'max_depth': 7, 'subsample': 0.4742530861711578, 'colsample_bytree': 0.3562125552171959, 'min_child_weight': 1}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 18:00:54,053] Trial 65 finished with value: 52.39876752615662 and parameters: {'n_estimators': 2337, 'learning_rate': 0.0037224103517780154, 'max_depth': 5, 'subsample': 0.46392284567975006, 'colsample_bytree': 0.41969341255272075, 'min_child_weight': 1}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 18:01:07,192] Trial 66 finished with value: 51.462695513721165 and parameters: {'n_estimators': 2500, 'learning_rate': 0.0015201162528960268, 'max_depth': 8, 'subsample': 0.383005476682015, 'colsample_bytree': 0.2890174114153985, 'min_child_weight': 4}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 18:01:14,562] Trial 67 finished with value: 51.71461604265513 and parameters: {'n_estimators': 2591, 'learning_rate': 0.003023022735708794, 'max_depth': 6, 'subsample': 0.5044054010382526, 'colsample_bytree': 0.32806292787168373, 'min_child_weight': 1}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 18:01:33,861] Trial 68 finished with value: 51.41863965088639 and parameters: {'n_estimators': 2433, 'learning_rate': 0.002496841702868787, 'max_depth': 9, 'subsample': 0.47748851474018983, 'colsample_bytree': 0.446355721065962, 'min_child_weight': 3}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 18:01:45,136] Trial 69 finished with value: 52.61972005404927 and parameters: {'n_estimators': 2181, 'learning_rate': 0.004873980685065852, 'max_depth': 10, 'subsample': 0.3985070659277598, 'colsample_bytree': 0.3859560321199409, 'min_child_weight': 13}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 18:01:49,219] Trial 70 finished with value: 51.893381502205045 and parameters: {'n_estimators': 2095, 'learning_rate': 0.0018513491435532131, 'max_depth': 4, 'subsample': 0.4362690824251739, 'colsample_bytree': 0.4900043025381964, 'min_child_weight': 2}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 18:01:58,952] Trial 71 finished with value: 51.184618571946444 and parameters: {'n_estimators': 2307, 'learning_rate': 0.002222282568651543, 'max_depth': 7, 'subsample': 0.5506988459839337, 'colsample_bytree': 0.3673426594624267, 'min_child_weight': 2}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 18:02:08,626] Trial 72 finished with value: 51.125227235295085 and parameters: {'n_estimators': 2248, 'learning_rate': 0.0019030814767724506, 'max_depth': 7, 'subsample': 0.57947245804577, 'colsample_bytree': 0.3332146587452786, 'min_child_weight': 1}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 18:02:24,335] Trial 73 finished with value: 52.32267675595685 and parameters: {'n_estimators': 2159, 'learning_rate': 0.0013450856994134787, 'max_depth': 8, 'subsample': 0.5840737212755621, 'colsample_bytree': 0.3197415403895798, 'min_child_weight': 1}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 18:02:35,998] Trial 74 finished with value: 51.08630609043359 and parameters: {'n_estimators': 2411, 'learning_rate': 0.001836671823875986, 'max_depth': 7, 'subsample': 0.6144973340440736, 'colsample_bytree': 0.41156749910553836, 'min_child_weight': 1}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 18:02:47,054] Trial 75 finished with value: 51.49861848749145 and parameters: {'n_estimators': 2369, 'learning_rate': 0.001614275457310322, 'max_depth': 7, 'subsample': 0.6207103742865913, 'colsample_bytree': 0.26204299236768225, 'min_child_weight': 1}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 18:03:06,249] Trial 76 finished with value: 52.18976148564892 and parameters: {'n_estimators': 2430, 'learning_rate': 0.0011516410136632469, 'max_depth': 8, 'subsample': 0.5950688358962021, 'colsample_bytree': 0.4067960470353672, 'min_child_weight': 1}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 18:03:12,465] Trial 77 finished with value: 51.625846892491346 and parameters: {'n_estimators': 1893, 'learning_rate': 0.0018213958111423653, 'max_depth': 6, 'subsample': 0.6525717165097104, 'colsample_bytree': 0.34108945183962386, 'min_child_weight': 3}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 18:03:27,552] Trial 78 finished with value: 51.96886220809946 and parameters: {'n_estimators': 2226, 'learning_rate': 0.002782241203553674, 'max_depth': 10, 'subsample': 0.6964511586956668, 'colsample_bytree': 0.44161588665424906, 'min_child_weight': 17}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 18:03:36,116] Trial 79 finished with value: 52.04051336427047 and parameters: {'n_estimators': 2010, 'learning_rate': 0.0014601970899801933, 'max_depth': 7, 'subsample': 0.6223251687066782, 'colsample_bytree': 0.38214996916695537, 'min_child_weight': 2}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 18:03:42,583] Trial 80 finished with value: 51.69548104289557 and parameters: {'n_estimators': 2530, 'learning_rate': 0.0024648299379557968, 'max_depth': 6, 'subsample': 0.5095655042494797, 'colsample_bytree': 0.2929589117804259, 'min_child_weight': 3}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 18:03:51,367] Trial 81 finished with value: 51.22218673329511 and parameters: {'n_estimators': 2318, 'learning_rate': 0.0018458061566553735, 'max_depth': 7, 'subsample': 0.5695003848305215, 'colsample_bytree': 0.3500004338973115, 'min_child_weight': 2}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 18:04:05,761] Trial 82 finished with value: 50.93336799620833 and parameters: {'n_estimators': 2213, 'learning_rate': 0.002057117147505638, 'max_depth': 8, 'subsample': 0.5257334067944931, 'colsample_bytree': 0.4051233747796767, 'min_child_weight': 1}. Best is trial 17 with value: 50.901244181077125.\n",
      "[I 2023-11-11 18:04:27,752] Trial 83 finished with value: 50.81496862861367 and parameters: {'n_estimators': 2221, 'learning_rate': 0.002138618539288638, 'max_depth': 9, 'subsample': 0.5971986012023756, 'colsample_bytree': 0.411073769984525, 'min_child_weight': 1}. Best is trial 83 with value: 50.81496862861367.\n",
      "[I 2023-11-11 18:04:47,843] Trial 84 finished with value: 50.95150016528171 and parameters: {'n_estimators': 2049, 'learning_rate': 0.0026447142638031124, 'max_depth': 9, 'subsample': 0.5228541422891401, 'colsample_bytree': 0.41352600164766423, 'min_child_weight': 1}. Best is trial 83 with value: 50.81496862861367.\n",
      "[I 2023-11-11 18:05:13,011] Trial 85 finished with value: 50.84840825202914 and parameters: {'n_estimators': 2072, 'learning_rate': 0.002637311985452389, 'max_depth': 9, 'subsample': 0.5202528490380127, 'colsample_bytree': 0.4123277851261505, 'min_child_weight': 1}. Best is trial 83 with value: 50.81496862861367.\n",
      "[I 2023-11-11 18:05:43,478] Trial 86 finished with value: 50.96817312113343 and parameters: {'n_estimators': 2078, 'learning_rate': 0.0026262758614588387, 'max_depth': 9, 'subsample': 0.516875686749323, 'colsample_bytree': 0.46928804995277296, 'min_child_weight': 1}. Best is trial 83 with value: 50.81496862861367.\n",
      "[I 2023-11-11 18:06:11,775] Trial 87 finished with value: 50.98324661878888 and parameters: {'n_estimators': 2067, 'learning_rate': 0.002636593516353074, 'max_depth': 9, 'subsample': 0.5248676033763255, 'colsample_bytree': 0.48440829824946474, 'min_child_weight': 1}. Best is trial 83 with value: 50.81496862861367.\n",
      "[I 2023-11-11 18:06:39,312] Trial 88 finished with value: 51.168694937133026 and parameters: {'n_estimators': 2061, 'learning_rate': 0.003004554747523559, 'max_depth': 9, 'subsample': 0.5205124691479085, 'colsample_bytree': 0.4702990001848463, 'min_child_weight': 1}. Best is trial 83 with value: 50.81496862861367.\n",
      "[I 2023-11-11 18:07:03,220] Trial 89 finished with value: 51.76795718568785 and parameters: {'n_estimators': 1988, 'learning_rate': 0.0026718657167757406, 'max_depth': 9, 'subsample': 0.45449826668169646, 'colsample_bytree': 0.5208875332275005, 'min_child_weight': 9}. Best is trial 83 with value: 50.81496862861367.\n",
      "[I 2023-11-11 18:07:30,974] Trial 90 finished with value: 51.487550981009804 and parameters: {'n_estimators': 1892, 'learning_rate': 0.0038251040426619345, 'max_depth': 10, 'subsample': 0.486129221531993, 'colsample_bytree': 0.49532031727773107, 'min_child_weight': 3}. Best is trial 83 with value: 50.81496862861367.\n",
      "[I 2023-11-11 18:07:55,703] Trial 91 finished with value: 51.27716309194286 and parameters: {'n_estimators': 1802, 'learning_rate': 0.0033777710688289594, 'max_depth': 9, 'subsample': 0.5149695292859491, 'colsample_bytree': 0.4256207653560918, 'min_child_weight': 1}. Best is trial 83 with value: 50.81496862861367.\n",
      "[I 2023-11-11 18:08:27,509] Trial 92 finished with value: 51.01515791131255 and parameters: {'n_estimators': 2081, 'learning_rate': 0.002516916468391692, 'max_depth': 9, 'subsample': 0.597681285893278, 'colsample_bytree': 0.4599357900045387, 'min_child_weight': 1}. Best is trial 83 with value: 50.81496862861367.\n",
      "[W 2023-11-11 18:09:46,868] Trial 93 failed with parameters: {'n_estimators': 2066, 'learning_rate': 0.0027007997144455017, 'max_depth': 10, 'subsample': 0.638817101680206, 'colsample_bytree': 0.46190003383946804, 'min_child_weight': 2} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shahl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\Shahl\\AppData\\Local\\Temp\\ipykernel_28952\\2769641949.py\", line 25, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, X_train_new_c, y_train_new_c), n_trials=100)\n",
      "  File \"C:\\Users\\Shahl\\AppData\\Local\\Temp\\ipykernel_28952\\2769641949.py\", line 19, in objective\n",
      "    model.fit(X_train_new_c, y_train_new_c, verbose=300)\n",
      "  File \"c:\\Users\\Shahl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Shahl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py\", line 1086, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Shahl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Shahl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Shahl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 2050, in update\n",
      "    _LIB.XGBoosterUpdateOneIter(\n",
      "KeyboardInterrupt\n",
      "[W 2023-11-11 18:09:46,872] Trial 93 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[39mreturn\u001b[39;00m MAE\n\u001b[0;32m     24\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m study\u001b[39m.\u001b[39;49moptimize(\u001b[39mlambda\u001b[39;49;00m trial: objective(trial, X_train_new_c, y_train_new_c), n_trials\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Shahl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     _optimize(\n\u001b[0;32m    452\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    453\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    454\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    455\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    456\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    457\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[0;32m    458\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    459\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    460\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    461\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Shahl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Shahl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\Shahl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[0;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    250\u001b[0m ):\n\u001b[1;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\Shahl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[0;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[5], line 25\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[39mreturn\u001b[39;00m MAE\n\u001b[0;32m     24\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m study\u001b[39m.\u001b[39moptimize(\u001b[39mlambda\u001b[39;00m trial: objective(trial, X_train_new_c, y_train_new_c), n_trials\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)\n",
      "Cell \u001b[1;32mIn[5], line 19\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial, X_train_new_c, y_train_new_c)\u001b[0m\n\u001b[0;32m      7\u001b[0m params \u001b[39m=\u001b[39m {\n\u001b[0;32m      8\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mn_estimators\u001b[39m\u001b[39m\"\u001b[39m: trial\u001b[39m.\u001b[39msuggest_int(\u001b[39m\"\u001b[39m\u001b[39mn_estimators\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m1000\u001b[39m, \u001b[39m3000\u001b[39m),\n\u001b[0;32m      9\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mverbosity\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[39m'\u001b[39m\u001b[39meval_metric\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mmae\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     16\u001b[0m }\n\u001b[0;32m     18\u001b[0m model \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mXGBRegressor(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[1;32m---> 19\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train_new_c, y_train_new_c, verbose\u001b[39m=\u001b[39;49m\u001b[39m300\u001b[39;49m)\n\u001b[0;32m     20\u001b[0m pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test_new_c)\n\u001b[0;32m     21\u001b[0m MAE \u001b[39m=\u001b[39m mean_absolute_error(y_test_c, pred)\n",
      "File \u001b[1;32mc:\\Users\\Shahl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Shahl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py:1086\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1075\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1077\u001b[0m (\n\u001b[0;32m   1078\u001b[0m     model,\n\u001b[0;32m   1079\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1084\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1085\u001b[0m )\n\u001b[1;32m-> 1086\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[0;32m   1087\u001b[0m     params,\n\u001b[0;32m   1088\u001b[0m     train_dmatrix,\n\u001b[0;32m   1089\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[0;32m   1090\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[0;32m   1091\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[0;32m   1092\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[0;32m   1093\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[0;32m   1094\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[0;32m   1095\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   1096\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m   1097\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   1098\u001b[0m )\n\u001b[0;32m   1100\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[0;32m   1101\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Shahl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Shahl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[0;32m    182\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Shahl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:2050\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2046\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2048\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2049\u001b[0m     _check_call(\n\u001b[1;32m-> 2050\u001b[0m         _LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\n\u001b[0;32m   2051\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle, ctypes\u001b[39m.\u001b[39;49mc_int(iteration), dtrain\u001b[39m.\u001b[39;49mhandle\n\u001b[0;32m   2052\u001b[0m         )\n\u001b[0;32m   2053\u001b[0m     )\n\u001b[0;32m   2054\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2055\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import optuna\n",
    "\n",
    "\n",
    "def objective(trial, X_train_new_c, y_train_new_c):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 1000, 3000),\n",
    "        \"verbosity\": 0,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 10),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1.0),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 20),\n",
    "        'eval_metric': 'mae'\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBRegressor(**params)\n",
    "    model.fit(X_train_new_c, y_train_new_c, verbose=300)\n",
    "    pred = model.predict(X_test_new_c)\n",
    "    MAE = mean_absolute_error(y_test_c, pred)\n",
    "    return MAE\n",
    "    \n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_new_c, y_train_new_c), n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
