{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andres/miniforge3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor\n",
    "from IPython.display import display\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_df(dataframes):\n",
    "    \"\"\"\n",
    "    Merges multiple pandas DataFrames on their index.\n",
    "\n",
    "    Parameters:\n",
    "    dataframes (list of pandas.DataFrame): The list of DataFrames to merge.\n",
    "    how (str): Type of merge to perform:\n",
    "        - 'left': use only keys from left frame (SQL: left outer join)\n",
    "        - 'right': use only keys from right frame (SQL: right outer join)\n",
    "        - 'outer': use union of keys from both frames (SQL: full outer join)\n",
    "        - 'inner': use intersection of keys from both frames (SQL: inner join)\n",
    "    remove_duplicates (bool): Whether to remove duplicated rows after merging.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: The merged DataFrame.\n",
    "    \"\"\"\n",
    "    # Start with the first DataFrame in the list\n",
    "    merged_df = dataframes[0]\n",
    "\n",
    "    # Iteratively merge each DataFrame in the list\n",
    "    for df in dataframes[1:]:\n",
    "        merged_df = merged_df.join(df, how='left')\n",
    "\n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_df(dataframes, axis='index'):\n",
    "    # Identify common columns by intersecting all DataFrame columns\n",
    "    common_columns = reduce(lambda x, y: x.intersection(y.columns), dataframes, dataframes[0].columns)\n",
    "\n",
    "    # Reindex all DataFrames to these common columns\n",
    "    dfs_common = [df[common_columns] for df in dataframes]\n",
    "\n",
    "    # Concatenate the reindexed DataFrames\n",
    "    return pd.concat(dfs_common, axis=axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_parquet(filepath,index=None,loc=None):\n",
    "    df = pd.read_parquet(filepath)\n",
    "    if index:\n",
    "        df.set_index(index, inplace=True)\n",
    "        df.index.name = 'index'\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        # df['timestamp'] = pd.to_datetime(df.index).astype('datetime64[ns]')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_time_delta(df):\n",
    "\n",
    "    data_sorted = df.sort_index()\n",
    "    time_deltas = data_sorted.index.to_series().diff().dropna()\n",
    "    non_zero_deltas = time_deltas[time_deltas != pd.Timedelta(0)]\n",
    "    min_time_delta = non_zero_deltas.min().total_seconds()\n",
    "\n",
    "    if min_time_delta < 3600:\n",
    "        # Convert to minutes\n",
    "        return f\"{min_time_delta // 60:.0f}T\"\n",
    "    else:\n",
    "        # Convert to hours\n",
    "        return f\"{min_time_delta // 3600:.0f}H\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train           = read_parquet('/home/andres/ml/data/A/train_targets.parquet',     'time',         'A')\n",
    "X_train_estimated = read_parquet('/home/andres/ml/data/A/X_train_estimated.parquet', 'date_forecast','A')\n",
    "X_train_observed  = read_parquet('/home/andres/ml/data/A/X_train_observed.parquet',  'date_forecast','A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 136245 entries, 2022-10-28 22:00:00 to 2022-10-21 01:00:00\n",
      "Data columns (total 45 columns):\n",
      " #   Column                          Non-Null Count   Dtype  \n",
      "---  ------                          --------------   -----  \n",
      " 0   absolute_humidity_2m:gm3        136245 non-null  float32\n",
      " 1   air_density_2m:kgm3             136245 non-null  float32\n",
      " 2   ceiling_height_agl:m            110079 non-null  float32\n",
      " 3   clear_sky_energy_1h:J           136245 non-null  float32\n",
      " 4   clear_sky_rad:W                 136245 non-null  float32\n",
      " 5   cloud_base_agl:m                126085 non-null  float32\n",
      " 6   dew_or_rime:idx                 136245 non-null  float32\n",
      " 7   dew_point_2m:K                  136245 non-null  float32\n",
      " 8   diffuse_rad:W                   136245 non-null  float32\n",
      " 9   diffuse_rad_1h:J                136245 non-null  float32\n",
      " 10  direct_rad:W                    136245 non-null  float32\n",
      " 11  direct_rad_1h:J                 136245 non-null  float32\n",
      " 12  effective_cloud_cover:p         136245 non-null  float32\n",
      " 13  elevation:m                     136245 non-null  float32\n",
      " 14  fresh_snow_12h:cm               136245 non-null  float32\n",
      " 15  fresh_snow_1h:cm                136245 non-null  float32\n",
      " 16  fresh_snow_24h:cm               136245 non-null  float32\n",
      " 17  fresh_snow_3h:cm                136245 non-null  float32\n",
      " 18  fresh_snow_6h:cm                136245 non-null  float32\n",
      " 19  is_day:idx                      136245 non-null  float32\n",
      " 20  is_in_shadow:idx                136245 non-null  float32\n",
      " 21  msl_pressure:hPa                136245 non-null  float32\n",
      " 22  precip_5min:mm                  136245 non-null  float32\n",
      " 23  precip_type_5min:idx            136245 non-null  float32\n",
      " 24  pressure_100m:hPa               136245 non-null  float32\n",
      " 25  pressure_50m:hPa                136245 non-null  float32\n",
      " 26  prob_rime:p                     136245 non-null  float32\n",
      " 27  rain_water:kgm2                 136245 non-null  float32\n",
      " 28  relative_humidity_1000hPa:p     136245 non-null  float32\n",
      " 29  sfc_pressure:hPa                136245 non-null  float32\n",
      " 30  snow_density:kgm3               4531 non-null    float32\n",
      " 31  snow_depth:cm                   136245 non-null  float32\n",
      " 32  snow_drift:idx                  136245 non-null  float32\n",
      " 33  snow_melt_10min:mm              136245 non-null  float32\n",
      " 34  snow_water:kgm2                 136245 non-null  float32\n",
      " 35  sun_azimuth:d                   136245 non-null  float32\n",
      " 36  sun_elevation:d                 136245 non-null  float32\n",
      " 37  super_cooled_liquid_water:kgm2  136245 non-null  float32\n",
      " 38  t_1000hPa:K                     136245 non-null  float32\n",
      " 39  total_cloud_cover:p             136245 non-null  float32\n",
      " 40  visibility:m                    136245 non-null  float32\n",
      " 41  wind_speed_10m:ms               136245 non-null  float32\n",
      " 42  wind_speed_u_10m:ms             136245 non-null  float32\n",
      " 43  wind_speed_v_10m:ms             136245 non-null  float32\n",
      " 44  wind_speed_w_1000hPa:ms         136245 non-null  float32\n",
      "dtypes: float32(45)\n",
      "memory usage: 24.4 MB\n"
     ]
    }
   ],
   "source": [
    "X_train = concat_df([X_train_estimated, X_train_observed])\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(data):\n",
    "\n",
    "    interpolation_methods = {\n",
    "        'absolute_humidity_2m:gm3': 'index',\n",
    "        'air_density_2m:kgm3': 'index',\n",
    "        'ceiling_height_agl:m': 'index',\n",
    "        'clear_sky_energy_1h:J': 'cubic',\n",
    "        'clear_sky_rad:W': 'cubic',\n",
    "        'cloud_base_agl:m': 'pchip',\n",
    "        'dew_or_rime:idx': 'nearest',\n",
    "        'dew_point_2m:K': 'linear',\n",
    "        'diffuse_rad:W': 'cubic',\n",
    "        'diffuse_rad_1h:J': 'cubic',\n",
    "        'direct_rad:W': 'cubic',\n",
    "        'direct_rad_1h:J': 'cubic',\n",
    "        'effective_cloud_cover:p': 'index',\n",
    "        'elevation:m': 'pad',\n",
    "        'fresh_snow_12h:cm': 'zero',\n",
    "        'fresh_snow_1h:cm': 'zero',\n",
    "        'fresh_snow_24h:cm': 'zero',\n",
    "        'fresh_snow_3h:cm': 'zero',\n",
    "        'fresh_snow_6h:cm': 'zero',\n",
    "        'is_day:idx': 'pad',\n",
    "        'is_in_shadow:idx': 'pad',\n",
    "        'msl_pressure:hPa': 'time',\n",
    "        'precip_5min:mm': 'index',\n",
    "        'precip_type_5min:idx': 'nearest',\n",
    "        'pressure_100m:hPa': 'index',\n",
    "        'pressure_50m:hPa': 'index',\n",
    "        'prob_rime:p': 'index',\n",
    "        'rain_water:kgm2': 'index',\n",
    "        'relative_humidity_1000hPa:p': 'index',\n",
    "        'sfc_pressure:hPa': 'time',\n",
    "        'snow_density:kgm3': 'zero',\n",
    "        'snow_depth:cm': 'nearest',\n",
    "        'snow_drift:idx': 'pad',\n",
    "        'snow_melt_10min:mm': 'index',\n",
    "        'snow_water:kgm2': 'index',\n",
    "        'sun_azimuth:d': 'cubic',\n",
    "        'sun_elevation:d': 'cubic',\n",
    "        'super_cooled_liquid_water:kgm2': 'index',\n",
    "        't_1000hPa:K': 'index',\n",
    "        'total_cloud_cover:p': 'index',\n",
    "        'visibility:m': 'index',\n",
    "        'wind_speed_10m:ms': 'index',\n",
    "        'wind_speed_u_10m:ms': 'index',\n",
    "        'wind_speed_v_10m:ms': 'index',\n",
    "        'wind_speed_w_1000hPa:ms': 'index',\n",
    "        'pv_measurement':'index'\n",
    "    }\n",
    "    for column in data.columns:\n",
    "        data[column].interpolate(method=interpolation_methods.get(column, 'linear'), inplace=True)\n",
    "        if data[column].isna().any():\n",
    "            print(column + ' has NaN, replacing NaN with 0.')\n",
    "            data[column] = data[column].fillna(0)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snow_density:kgm3 has NaN, replacing NaN with 0.\n",
      "index\n",
      "2019-06-02 22:00:00   2019-06-02 22:00:00\n",
      "2019-06-02 22:15:00   2019-06-02 22:15:00\n",
      "2019-06-02 22:30:00   2019-06-02 22:30:00\n",
      "2019-06-02 22:45:00   2019-06-02 22:45:00\n",
      "2019-06-02 23:00:00   2019-06-02 23:00:00\n",
      "                              ...        \n",
      "2023-04-30 22:45:00   2023-04-30 22:45:00\n",
      "2023-04-30 23:00:00   2023-04-30 23:00:00\n",
      "2023-04-30 23:15:00   2023-04-30 23:15:00\n",
      "2023-04-30 23:30:00   2023-04-30 23:30:00\n",
      "2023-04-30 23:45:00   2023-04-30 23:45:00\n",
      "Freq: 15T, Name: timestamp, Length: 137096, dtype: datetime64[ns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42982/658097509.py:52: FutureWarning: Series.interpolate with method=pad is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data[column].interpolate(method=interpolation_methods.get(column, 'linear'), inplace=True)\n",
      "/tmp/ipykernel_42982/658097509.py:52: FutureWarning: Series.interpolate with method=pad is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data[column].interpolate(method=interpolation_methods.get(column, 'linear'), inplace=True)\n",
      "/tmp/ipykernel_42982/658097509.py:52: FutureWarning: Series.interpolate with method=pad is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data[column].interpolate(method=interpolation_methods.get(column, 'linear'), inplace=True)\n",
      "/tmp/ipykernel_42982/658097509.py:52: FutureWarning: Series.interpolate with method=pad is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data[column].interpolate(method=interpolation_methods.get(column, 'linear'), inplace=True)\n",
      "/tmp/ipykernel_42982/658097509.py:52: FutureWarning: Series.interpolate with method=pad is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data[column].interpolate(method=interpolation_methods.get(column, 'linear'), inplace=True)\n",
      "/tmp/ipykernel_42982/658097509.py:52: FutureWarning: Series.interpolate with method=pad is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data[column].interpolate(method=interpolation_methods.get(column, 'linear'), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "freq = get_min_time_delta(X_train)\n",
    "X_train = X_train.resample(freq).asfreq(fill_value=None)\n",
    "train_data = merge_df([interpolate(X_train),interpolate(Y_train)])\n",
    "interpolate(train_data)\n",
    "train_data['timestamp'] = train_data.index.astype('datetime64[ns]')\n",
    "print(train_data['timestamp'])\n",
    "train_data['location'] = 'A'\n",
    "train_data = TimeSeriesDataFrame.from_data_frame(\n",
    "    train_data,\n",
    "    id_column=\"location\",\n",
    "    timestamp_column=\"timestamp\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                id  prediction\n",
      "location time                                 \n",
      "A        2023-05-01 00:00:00     0           0\n",
      "         2023-05-01 01:00:00     1           0\n",
      "         2023-05-01 02:00:00     2           0\n",
      "         2023-05-01 03:00:00     3           0\n",
      "         2023-05-01 04:00:00     4           0\n",
      "...                            ...         ...\n",
      "C        2023-07-03 19:00:00  2155           0\n",
      "         2023-07-03 20:00:00  2156           0\n",
      "         2023-07-03 21:00:00  2157           0\n",
      "         2023-07-03 22:00:00  2158           0\n",
      "         2023-07-03 23:00:00  2159           0\n",
      "\n",
      "[2160 rows x 2 columns]\n",
      "                      id  prediction\n",
      "time                                \n",
      "2023-05-01 00:00:00    0           0\n",
      "2023-05-01 01:00:00    1           0\n",
      "2023-05-01 02:00:00    2           0\n",
      "2023-05-01 03:00:00    3           0\n",
      "2023-05-01 04:00:00    4           0\n",
      "...                  ...         ...\n",
      "2023-07-03 19:00:00  715           0\n",
      "2023-07-03 20:00:00  716           0\n",
      "2023-07-03 21:00:00  717           0\n",
      "2023-07-03 22:00:00  718           0\n",
      "2023-07-03 23:00:00  719           0\n",
      "\n",
      "[720 rows x 2 columns]\n",
      "1H\n",
      "1536\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('/home/andres/ml/data/test.csv', index_col=['location', 'time'], parse_dates=['time'])\n",
    "# test.index.rename(names={'time': 'index', 'location': 'location'}, inplace=True)\n",
    "print(test)\n",
    "sub_df = test.loc['A']\n",
    "test = sub_df\n",
    "# print(sub_df)\n",
    "# freq = get_min_time_delta(sub_df)\n",
    "# print(freq)\n",
    "# test = sub_df.resample(freq).asfreq(fill_value=None)\n",
    "num_predictions = test.shape[0]\n",
    "print(num_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data_s, test_data_s) = train_data.train_test_split(prediction_length=num_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42982/658097509.py:52: FutureWarning: Series.interpolate with method=pad is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data[column].interpolate(method=interpolation_methods.get(column, 'linear'), inplace=True)\n",
      "/tmp/ipykernel_42982/658097509.py:52: FutureWarning: Series.interpolate with method=pad is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data[column].interpolate(method=interpolation_methods.get(column, 'linear'), inplace=True)\n",
      "/tmp/ipykernel_42982/658097509.py:52: FutureWarning: Series.interpolate with method=pad is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data[column].interpolate(method=interpolation_methods.get(column, 'linear'), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snow_density:kgm3 has NaN, replacing NaN with 0.\n",
      "index\n",
      "2023-05-01 00:00:00   2023-05-01 00:00:00\n",
      "2023-05-01 00:15:00   2023-05-01 00:15:00\n",
      "2023-05-01 00:30:00   2023-05-01 00:30:00\n",
      "2023-05-01 00:45:00   2023-05-01 00:45:00\n",
      "2023-05-01 01:00:00   2023-05-01 01:00:00\n",
      "                              ...        \n",
      "2023-07-03 22:45:00   2023-07-03 22:45:00\n",
      "2023-07-03 23:00:00   2023-07-03 23:00:00\n",
      "2023-07-03 23:15:00   2023-07-03 23:15:00\n",
      "2023-07-03 23:30:00   2023-07-03 23:30:00\n",
      "2023-07-03 23:45:00   2023-07-03 23:45:00\n",
      "Freq: 15T, Name: timestamp, Length: 6144, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "X_pred = read_parquet('/home/andres/ml/data/A/X_test_estimated.parquet',  'date_forecast','A')\n",
    "freq = get_min_time_delta(X_pred)\n",
    "X_pred = X_pred.resample(freq).asfreq(fill_value=None)\n",
    "interpolate(X_pred)\n",
    "X_pred['timestamp'] = X_pred.index.astype('datetime64[ns]')\n",
    "print(X_pred['timestamp'])\n",
    "X_pred['location'] = 'A'\n",
    "X_pred = TimeSeriesDataFrame.from_data_frame(\n",
    "    X_pred,\n",
    "    id_column=\"location\",\n",
    "    timestamp_column=\"timestamp\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n"
     ]
    }
   ],
   "source": [
    "print(num_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"autogluon\"\n",
      "================ TimeSeriesPredictor ================\n",
      "TimeSeriesPredictor.fit() called\n",
      "Setting presets to: fast_training\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'evaluation_metric': 'MSE',\n",
      " 'excluded_model_types': None,\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'hyperparameters': 'fast_training',\n",
      " 'num_val_windows': 1,\n",
      " 'prediction_length': 1536,\n",
      " 'random_seed': None,\n",
      " 'target': 'pv_measurement',\n",
      " 'time_limit': 600,\n",
      " 'verbosity': 2}\n",
      "Provided training data set with 135560 rows, 1 items (item = single time series). Average time series length is 135560.0. Data frequency is '15T'.\n",
      "=====================================================\n",
      "AutoGluon will save models to autogluon/\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'MSE'\n",
      "\tThis metric's sign has been flipped to adhere to being 'higher is better'. The reported score can be multiplied by -1 to get the metric value.\n",
      "\n",
      "Provided dataset contains following columns:\n",
      "\ttarget:           'pv_measurement'\n",
      "\tpast covariates:  ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', 'cloud_base_agl:m', 'dew_or_rime:idx', 'dew_point_2m:K', 'diffuse_rad:W', 'diffuse_rad_1h:J', 'direct_rad:W', 'direct_rad_1h:J', 'effective_cloud_cover:p', 'elevation:m', 'fresh_snow_12h:cm', 'fresh_snow_1h:cm', 'fresh_snow_24h:cm', 'fresh_snow_3h:cm', 'fresh_snow_6h:cm', 'is_day:idx', 'is_in_shadow:idx', 'msl_pressure:hPa', 'precip_5min:mm', 'precip_type_5min:idx', 'pressure_100m:hPa', 'pressure_50m:hPa', 'prob_rime:p', 'rain_water:kgm2', 'relative_humidity_1000hPa:p', 'sfc_pressure:hPa', 'snow_density:kgm3', 'snow_depth:cm', 'snow_drift:idx', 'snow_melt_10min:mm', 'snow_water:kgm2', 'sun_azimuth:d', 'sun_elevation:d', 'super_cooled_liquid_water:kgm2', 't_1000hPa:K', 'total_cloud_cover:p', 'visibility:m', 'wind_speed_10m:ms', 'wind_speed_u_10m:ms', 'wind_speed_v_10m:ms', 'wind_speed_w_1000hPa:ms']\n",
      "\n",
      "Starting training. Start time is 2023-11-11 00:28:43\n",
      "Models that will be trained: ['Naive', 'SeasonalNaive', 'Theta', 'ETS', 'RecursiveTabular']\n",
      "Training timeseries model Naive. Training for up to 599.86s of the 599.86s of remaining time.\n",
      "\t-4262677.2174 = Validation score (-MSE)\n",
      "\t0.09    s     = Training runtime\n",
      "\t1.75    s     = Validation (prediction) runtime\n",
      "Training timeseries model SeasonalNaive. Training for up to 598.01s of the 598.01s of remaining time.\n",
      "\t-557402.4891  = Validation score (-MSE)\n",
      "\t0.10    s     = Training runtime\n",
      "\t1.57    s     = Validation (prediction) runtime\n",
      "Training timeseries model Theta. Training for up to 596.34s of the 596.34s of remaining time.\n",
      "\t-1539922.3913 = Validation score (-MSE)\n",
      "\t0.09    s     = Training runtime\n",
      "\t13.19   s     = Validation (prediction) runtime\n",
      "Training timeseries model ETS. Training for up to 583.05s of the 583.05s of remaining time.\n",
      "\t-2811896.4994 = Validation score (-MSE)\n",
      "\t0.09    s     = Training runtime\n",
      "\t5.70    s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. Training for up to 577.25s of the 577.25s of remaining time.\n",
      "\t-499111.4629  = Validation score (-MSE)\n",
      "\t3.85    s     = Training runtime\n",
      "\t17.98   s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\t-378283.5214  = Validation score (-MSE)\n",
      "\t0.83    s     = Training runtime\n",
      "\t34.48   s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['Naive', 'SeasonalNaive', 'Theta', 'ETS', 'RecursiveTabular', 'WeightedEnsemble']\n",
      "Total runtime: 45.46 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -378283.5214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.timeseries.predictor.TimeSeriesPredictor at 0x7f0d8a3184f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = TimeSeriesPredictor(\n",
    "    prediction_length=num_predictions,\n",
    "    path=\"autogluon\",\n",
    "    target=\"pv_measurement\",\n",
    "    eval_metric=\"MSE\",\n",
    ")\n",
    "\n",
    "predictor.fit(\n",
    "    train_data_s,\n",
    "    presets=\"fast_training\",\n",
    "    time_limit=600,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Additional data provided, testing on additional data. Resulting leaderboard will be sorted according to test score (`score_test`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              model    score_test     score_val  pred_time_test  \\\n",
      "0             Theta -1.069123e+06 -1.539922e+06       13.160655   \n",
      "1  WeightedEnsemble -1.278381e+06 -3.782835e+05       33.163072   \n",
      "2  RecursiveTabular -1.303030e+06 -4.991115e+05       16.849710   \n",
      "3     SeasonalNaive -1.352936e+06 -5.574025e+05        1.577496   \n",
      "4             Naive -3.000111e+06 -4.262677e+06        1.572455   \n",
      "5               ETS -1.327486e+07 -2.811896e+06        7.362496   \n",
      "\n",
      "   pred_time_val  fit_time_marginal  fit_order  \n",
      "0      13.187943           0.093085          3  \n",
      "1      34.480164           0.830675          6  \n",
      "2      17.976666           3.847470          5  \n",
      "3       1.570396           0.095502          2  \n",
      "4       1.745158           0.094488          1  \n",
      "5       5.704984           0.093964          4  \n"
     ]
    }
   ],
   "source": [
    "print(predictor.leaderboard(test_data_s, silent=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1278380.9952781294"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(test_data_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 123\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'autogluon.timeseries.dataset.ts_dataframe.TimeSeriesDataFrame'>\n",
      "MultiIndex: 1536 entries, ('A', Timestamp('2023-05-01 00:00:00')) to ('A', Timestamp('2023-05-16 23:45:00'))\n",
      "Data columns (total 10 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   mean    1536 non-null   float64\n",
      " 1   0.1     1536 non-null   float64\n",
      " 2   0.2     1536 non-null   float64\n",
      " 3   0.3     1536 non-null   float64\n",
      " 4   0.4     1536 non-null   float64\n",
      " 5   0.5     1536 non-null   float64\n",
      " 6   0.6     1536 non-null   float64\n",
      " 7   0.7     1536 non-null   float64\n",
      " 8   0.8     1536 non-null   float64\n",
      " 9   0.9     1536 non-null   float64\n",
      "dtypes: float64(10)\n",
      "memory usage: 136.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "predictions = predictor.predict(train_data, known_covariates=X_pred)\n",
    "print(predictions.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n"
     ]
    }
   ],
   "source": [
    "print(num_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
