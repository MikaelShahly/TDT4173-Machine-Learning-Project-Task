{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Random prediction\n",
    "\n",
    "For the first prediction we experimented with and creating a submission with random values to set as a baseline for future attempts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_directory_tree_with_os_walk(starting_directory):\n",
    "    for root, directories, files in os.walk(starting_directory):\n",
    "        print(f\"Directory: {root}\")\n",
    "        for file in files:\n",
    "            print(f\"  File: {file}\")\n",
    "\n",
    "list_directory_tree_with_os_walk('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_a = pd.read_parquet('data/A/train_targets.parquet')\n",
    "train_b = pd.read_parquet('data/B/train_targets.parquet')\n",
    "train_c = pd.read_parquet('data/C/train_targets.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_estimated_a = pd.read_parquet('data/A/X_train_estimated.parquet')\n",
    "X_train_estimated_b = pd.read_parquet('data/B/X_train_estimated.parquet')\n",
    "X_train_estimated_c = pd.read_parquet('data/C/X_train_estimated.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_observed_a = pd.read_parquet('data/A/X_train_observed.parquet')\n",
    "X_train_observed_b = pd.read_parquet('data/B/X_train_observed.parquet')\n",
    "X_train_observed_c = pd.read_parquet('data/C/X_train_observed.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_estimated_a = pd.read_parquet('data/A/X_test_estimated.parquet')\n",
    "X_test_estimated_b = pd.read_parquet('data/B/X_test_estimated.parquet')\n",
    "X_test_estimated_c = pd.read_parquet('data/C/X_test_estimated.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a single feature\n",
    "fig, axs = plt.subplots(3, 1, figsize=(20, 10), sharex=True)\n",
    "feature_name = 'absolute_humidity_2m:gm3'\n",
    "X_train_observed_a[['date_forecast', feature_name]].set_index('date_forecast').plot(ax=axs[0], title='Train/Test A', color='red')\n",
    "X_train_estimated_a[['date_forecast', feature_name]].set_index('date_forecast').plot(ax=axs[0], title='Train/Test A', color='blue')\n",
    "X_test_estimated_a[['date_forecast', feature_name]].set_index('date_forecast').plot(ax=axs[0], title='Train/Test  A', color='green')\n",
    "\n",
    "X_train_observed_b[['date_forecast', feature_name]].set_index('date_forecast').plot(ax=axs[1], title='Train/Test  B', color='red')\n",
    "X_train_estimated_b[['date_forecast', feature_name]].set_index('date_forecast').plot(ax=axs[1], title='Train/Test  B', color='blue')\n",
    "X_test_estimated_b[['date_forecast', feature_name]].set_index('date_forecast').plot(ax=axs[1], title='Train/Test  B', color='green')\n",
    "\n",
    "X_train_observed_c[['date_forecast', feature_name]].set_index('date_forecast').plot(ax=axs[2], title='Train/Test  C', color='red')\n",
    "X_train_estimated_c[['date_forecast', feature_name]].set_index('date_forecast').plot(ax=axs[2], title='Train/Test  C', color='blue')\n",
    "X_test_estimated_c[['date_forecast', feature_name]].set_index('date_forecast').plot(ax=axs[2], title='Train/Test  C', color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/test.csv')\n",
    "test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example, let the predictions be random values\n",
    "test['prediction'] = np.random.rand(len(test))\n",
    "sample_submission = sample_submission[['id']].merge(test[['id', 'prediction']], on='id', how='left')\n",
    "sample_submission.to_csv('my_first_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Decision Tree\n",
    "\n",
    "The second submission was based on the previous code but now using a basic Decision Tree regressor from SKLearn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making combined dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove all non hourly values\n",
    "X_train_all_a.set_index('date_forecast', inplace=True)\n",
    "mask = X_train_all_a.index.minute == 0\n",
    "X_train_all_a = X_train_all_a[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop([\"pv_measurement\",'date_calc'], axis=1)\n",
    "y = data.pv_measurement\n",
    "\n",
    "model = DecisionTreeRegressor(random_state=1)\n",
    "model.fit(X, y)\n",
    "predictions = model.predict(X_test_a.drop(['date_forecast', 'date_calc'], axis=1))\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/test.csv')\n",
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "test['prediction'] = np.random.rand(len(test))\n",
    "test.prediction[0..predictions.size] = predictions\n",
    "sample_submission = sample_submission[['id']].merge(test[['id', 'prediction']], on='id', how='left')\n",
    "sample_submission.to_csv('my_first_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis\n",
    "\n",
    "This is the initial Exploratory Data Analysis we made. This notebook contains also a Decision Tree regressor but now has better logic for creating the submission file."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project task - Solar Energy Production\n",
    "This notebook will contain the exploratory data analysis, all manipulation and cleaning of the given datasets and finally the creation of predictions using the different ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary datasets\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "#Setting max display options to avoid local crashes\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_a = pd.read_parquet('data/A/train_targets.parquet')\n",
    "Y_train_b = pd.read_parquet('data/B/train_targets.parquet')\n",
    "Y_train_c = pd.read_parquet('data/C/train_targets.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_estimated_a = pd.read_parquet('data/A/X_train_estimated.parquet')\n",
    "X_train_estimated_b = pd.read_parquet('data/B/X_train_estimated.parquet')\n",
    "X_train_estimated_c = pd.read_parquet('data/C/X_train_estimated.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_observed_a = pd.read_parquet('data/A/X_train_observed.parquet')\n",
    "X_train_observed_b = pd.read_parquet('data/B/X_train_observed.parquet')\n",
    "X_train_observed_c = pd.read_parquet('data/C/X_train_observed.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_estimated_a = pd.read_parquet('data/A/X_test_estimated.parquet')\n",
    "X_test_estimated_b = pd.read_parquet('data/B/X_test_estimated.parquet')\n",
    "X_test_estimated_c = pd.read_parquet('data/C/X_test_estimated.parquet')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining the datasets\n",
    "A seperate combined dataset will be made for the A, B and C location.\\\n",
    "Each location will have a X dataset (containing only feature values) and a complete training dataset (X_train combined with the Y_train values) which can be used to check for feature correlation. \n",
    "\n",
    "\n",
    "*Note: The resolution is different between the X and Y datasets, as Y each row in Y contains an hour and each row in X is per 15 minutes. To begin with the X datset will be naivly changed to have a resolution of every hour aswell. However we will later explore feature exploration techniques to retain more data from X by artifically increasing the resolution of the Y data*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Location A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the X dataset for location A\n",
    "X_train_estimated_a[\"estimated\"] = 1.0\n",
    "X_test_estimated_a[\"estimated\"] = 1.0\n",
    "X_train_observed_a[\"estimated\"] = 0.0\n",
    "X_train_observed_a[\"date_calc\"] = X_train_observed_a[\"date_forecast\"].copy() #date calc column added to observed data so that observed and estimated has equal nr cols\n",
    "\n",
    "X_train_estimated_a[\"train/test\"] = \"train\"\n",
    "X_train_observed_a[\"train/test\"] = \"train\"\n",
    "X_test_estimated_a[\"train/test\"] = \"test\"\n",
    "\n",
    "X_all_a= pd.concat([X_train_observed_a, X_train_estimated_a, X_test_estimated_a], ignore_index=True)\n",
    "X_all_a.set_index('date_forecast', inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Create the complete training set for A*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the complete train dataset for location A\n",
    "train_all_a = pd.concat([X_train_observed_a.drop(\"train/test\", axis=1), X_train_estimated_a.drop(\"train/test\", axis=1)], ignore_index=True)\n",
    "train_all_a.set_index('date_forecast', inplace=True)\n",
    "\n",
    "#remove all non hourly values\n",
    "train_all_a = train_all_a[train_all_a.index.minute == 0]\n",
    "\n",
    "#Set the index as the date forecast for y aswell\n",
    "Y_train_a.set_index('time', inplace=True)\n",
    "\n",
    "#Concatenate with y data\n",
    "train_all_a = pd.concat([train_all_a, Y_train_a], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_a.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Location B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine all data from B\n",
    "X_train_estimated_b[\"estimated\"] = 1.0\n",
    "X_test_estimated_b[\"estimated\"] = 1.0\n",
    "X_train_observed_b[\"estimated\"] = 0.0\n",
    "X_train_observed_b[\"date_calc\"] = X_train_observed_b[\"date_forecast\"].copy()\n",
    "\n",
    "X_train_estimated_b[\"train/test\"] = \"train\"\n",
    "X_train_observed_b[\"train/test\"] = \"train\"\n",
    "X_test_estimated_b[\"train/test\"] = \"test\"\n",
    "\n",
    "X_all_b= pd.concat([X_train_observed_b, X_train_estimated_b, X_test_estimated_b], ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Create the complete training set*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the complete train dataset for location A\n",
    "train_all_b = pd.concat([X_train_observed_b.drop(\"train/test\", axis=1), X_train_estimated_b.drop(\"train/test\", axis=1)], ignore_index=True)\n",
    "train_all_b.set_index('date_forecast', inplace=True)\n",
    "#remove all non hourly values\n",
    "train_all_b = train_all_b[train_all_b.index.minute == 0]\n",
    "\n",
    "#Set the index as the date forecast for y aswell\n",
    "Y_train_b.set_index('time', inplace=True)\n",
    "\n",
    "#Concatenate with y data\n",
    "train_all_b = pd.concat([train_all_b, Y_train_b], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the first row, as it is not in the X data\n",
    "train_all_b.drop(\"2018-12-31 23:00:00\", inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Location C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine all data from C\n",
    "X_train_estimated_c[\"estimated\"] = 1.0\n",
    "X_test_estimated_c[\"estimated\"] = 1.0\n",
    "X_train_observed_c[\"estimated\"] = 0.0\n",
    "X_train_observed_c[\"date_calc\"] = X_train_observed_c[\"date_forecast\"].copy()\n",
    "X_train_estimated_c[\"train/test\"] = \"train\"\n",
    "X_train_observed_c[\"train/test\"] = \"train\"\n",
    "X_test_estimated_c[\"train/test\"] = \"test\"\n",
    "\n",
    "X_all_c= pd.concat([X_train_observed_c, X_train_estimated_c, X_test_estimated_c], ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Create Complete training data for location C*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the complete train dataset for location A\n",
    "train_all_c = pd.concat([X_train_observed_c.drop(\"train/test\", axis=1), X_train_estimated_c.drop(\"train/test\", axis=1)], ignore_index=True)\n",
    "train_all_c.set_index('date_forecast', inplace=True)\n",
    "#remove all non hourly values\n",
    "train_all_c = train_all_c[train_all_c.index.minute == 0]\n",
    "\n",
    "#Set the index as the date forecast for y aswell\n",
    "Y_train_c.set_index('time', inplace=True)\n",
    "\n",
    "#Concatenate with y data\n",
    "train_all_c = pd.concat([train_all_c, Y_train_c], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_c.drop(\"2018-12-31 23:00:00\", inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets make a combined dataset for all locations\n",
    "This is in order to quickly check correlations and get a brief overview about all locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_a = X_all_a.copy()\n",
    "copy_b = X_all_b.copy()\n",
    "copy_c = X_all_c.copy()\n",
    "\n",
    "copy_a[\"location\"] = \"A\"\n",
    "copy_b[\"location\"] = \"B\"\n",
    "copy_c[\"location\"] = \"C\"\n",
    "X_all = pd.concat([copy_a, copy_b, copy_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_a_train = train_all_a.copy()\n",
    "copy_b_train = train_all_b.copy()\n",
    "copy_c_train = train_all_c.copy()\n",
    "\n",
    "copy_a_train[\"location\"] = \"A\"\n",
    "copy_b_train[\"location\"] = \"B\"\n",
    "copy_c_train[\"location\"] = \"C\"\n",
    "\n",
    "train_all = pd.concat([copy_a_train, copy_b_train, copy_c_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start by making some quick graphs of the all the data combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=17, ncols=3, figsize=(30, 100))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, column in enumerate(X_all.drop(\"date_calc\", axis=1).columns):\n",
    "    sns.histplot(data=X_all[column], kde=False, ax=axes[i])\n",
    "    axes[i].set_xlabel(column, fontsize = 20)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "- Based on this is seems like snow density is completely filled with Nan values\n",
    "- We have a random dip in the date forecast at the end of 2022\n",
    "- Snow Density has VERY low count compared to the other features\n",
    "- All the radian features have a strange distribution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets start to look at the correlation between the data and the target y values (PV measurement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (50, 60), dpi=200)\n",
    "sns.heatmap(train_all.drop([\"location\"], axis=1).corr(), annot = True); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (50,90), dpi=200)\n",
    "sns.heatmap(train_all.drop([\"location\"], axis=1).corr()[[\"pv_measurement\"]], annot = True); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all.drop([\"location\"], axis=1).corr()[[\"pv_measurement\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Notes*\n",
    "- wind_speed_w_1000hPa:ms seems to not be very important\n",
    "- All snow values seem to not be very important (except maybe snow depth)\n",
    "- dew_or_rime:idx is very useless"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_a = train_all_a.dropna(axis=0).drop(['date_calc', 'estimated'], axis=1)\n",
    "data_b = train_all_b.dropna(axis=0).drop(['date_calc', 'estimated'], axis=1)\n",
    "data_c = train_all_c.dropna(axis=0).drop(['date_calc', 'estimated'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor \n",
    "\n",
    "X_t = data_a.drop('pv_measurement',axis=1)\n",
    "y_t = data_a.pv_measurement\n",
    "model = DecisionTreeRegressor(random_state=1)\n",
    "model.fit(X_t, y_t)\n",
    "X_p = X_test_estimated_a.drop(['date_forecast', 'date_calc', 'estimated', 'train/test'], axis = 1)\n",
    "predictions = model.predict(X_p)\n",
    "out_pd = pd.concat([X_test_estimated_a.date_forecast, pd.DataFrame(predictions)], axis=1)\n",
    "out_pd=out_pd.rename(columns = {0:'prediction','date_forecast':'time'})\n",
    "out_pd['location'] = 'A'\n",
    "out_pd.set_index('time',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/test.csv')\n",
    "test.time = pd.to_datetime(test.time)\n",
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "# test['prediction'] = np.random.rand(len(test))\n",
    "test.set_index('time',inplace=True)\n",
    "df1 = test\n",
    "df2 = out_pd\n",
    "\n",
    "merged_df = df1.reset_index().merge(df2.reset_index(), on=['time', 'location'], how='left', suffixes=('_original', '_new'))\n",
    "\n",
    "# # Use combine_first to replace NaN values in 'prediction_new' with the original 'prediction' values\n",
    "merged_df['prediction_new'] = merged_df['prediction_new'].combine_first(merged_df['prediction_original'])\n",
    "\n",
    "# # Drop the original 'prediction' column\n",
    "merged_df.drop('prediction_original', axis=1, inplace=True)\n",
    "\n",
    "# # Rename 'prediction_new' to 'prediction'\n",
    "merged_df.rename(columns={'prediction_new': 'prediction'}, inplace=True)\n",
    "\n",
    "sample_submission = sample_submission[['id']].merge(merged_df[['id', 'prediction']], on='id', how='left')\n",
    "sample_submission.to_csv('my_first_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle competitions submit -c solar-energy-production-forecasting -f submission.csv -m \"Message\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autosklearn Classifier\n",
    "\n",
    "We then tried to improve the code from above by using AutoSKLearn, in this case it is mistakenly a classifier. Most of the code remains the same but using a different model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autosklearn.classification\n",
    "\n",
    "X_t = data_a.drop('pv_measurement',axis=1)\n",
    "y_t = data_a.pv_measurement\n",
    "model = autosklearn.classification.AutoSklearnClassifier(random_state=1)\n",
    "model.fit(X_t, y_t)\n",
    "X_p = X_test_estimated_a.drop(['date_forecast', 'date_calc', 'estimated', 'train/test'], axis = 1)\n",
    "predictions = model.predict(X_p)\n",
    "out_pd = pd.concat([X_test_estimated_a.date_forecast, pd.DataFrame(predictions)], axis=1)\n",
    "out_pd=out_pd.rename(columns = {0:'prediction','date_forecast':'time'})\n",
    "out_pd['location'] = 'A'\n",
    "out_pd.set_index('time',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Python script\n",
    "\n",
    "For the next few attempts, we moved to a Python script to try different models, this initial script now uses the Decision Tree regressor that is more suitable for our scenario. It also contains extra helper functions and better formatting with the help from ChatGPT. Here we started to also do some model evaluation with included cross-validation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import subprocess\n",
    "import argparse\n",
    "\n",
    "def execute_cmd(command):\n",
    "    \"\"\"\n",
    "    Execute a command using the command line.\n",
    "    \n",
    "    Parameters:\n",
    "    - command (str): The command to be executed.\n",
    "\n",
    "    Returns:\n",
    "    - str: The output of the command.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Run the command and get the output\n",
    "        result = subprocess.check_output(command, shell=True, stderr=subprocess.STDOUT, text=True)\n",
    "        return result.strip()\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        # If the command returns a non-zero exit code, an exception will be raised.\n",
    "        # Here, we catch the exception and return the error output.\n",
    "        return e.output.strip()\n",
    "\n",
    "def one_hot_to_categorical(df, col1, col2):\n",
    "    \"\"\"\n",
    "    Convert one-hot encoded columns to a single categorical column.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame containing the one-hot encoded columns.\n",
    "    - col1: Name of the first one-hot encoded column.\n",
    "    - col2: Name of the second one-hot encoded column.\n",
    "\n",
    "    Returns:\n",
    "    - A DataFrame with the categorical values.\n",
    "    \"\"\"\n",
    "    conditions = [\n",
    "        (df[col1] == 1),\n",
    "        (df[col2] == 1)\n",
    "    ]\n",
    "    choices = [col1, col2]\n",
    "    result_df = pd.DataFrame({\n",
    "        'Category': np.select(conditions, choices, default='A')\n",
    "    })\n",
    "    return result_df\n",
    "\n",
    "def load_datasets():\n",
    "    X_test  = pd.read_parquet('data/prepared_datasets/no_Nan_hotone_encoding/X_test.parquet')\n",
    "    X_train = pd.read_parquet('data/prepared_datasets/no_Nan_hotone_encoding/X_train.parquet')\n",
    "    Y_train = pd.read_parquet('data/prepared_datasets/no_Nan_hotone_encoding/Y_train.parquet')\n",
    "    return X_train, Y_train, X_test\n",
    "\n",
    "def train_and_predict(X_train, Y_train, X_test):\n",
    "    model = DecisionTreeRegressor(random_state=1)\n",
    "    scores = cross_val_score(model, X_train, Y_train, cv=5)\n",
    "    print(\"Cross-validation scores:\", scores)\n",
    "    print(\"Average cross-validation score:\", scores.mean())\n",
    "    model.fit(X_train, Y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    return predictions\n",
    "\n",
    "def prepare_submission(predictions, X_test):\n",
    "    pd_predictions = pd.DataFrame(predictions)\n",
    "    index_df = X_test.index.to_frame()\n",
    "    out_pd = pd.concat([index_df.reset_index(drop=True), pd_predictions.reset_index(drop=True)], axis=1)\n",
    "    out_pd = out_pd.rename(columns={0: 'prediction', 'date_forecast': 'time'})\n",
    "    out_pd['location'] = one_hot_to_categorical(X_test, 'B', 'C')\n",
    "    out_pd.set_index('time', inplace=True)\n",
    "    return out_pd\n",
    "\n",
    "def merge_with_sample(out_pd):\n",
    "    test = pd.read_csv('data/test.csv')\n",
    "    test.time = pd.to_datetime(test.time)\n",
    "    sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "    test.set_index('time', inplace=True)\n",
    "    \n",
    "    merged_df = test.reset_index().merge(out_pd.reset_index(), on=['time', 'location'], how='left', suffixes=('_original', '_new'))\n",
    "    merged_df['prediction_new'] = merged_df['prediction_new'].combine_first(merged_df['prediction_original'])\n",
    "    merged_df.drop('prediction_original', axis=1, inplace=True)\n",
    "    merged_df.rename(columns={'prediction_new': 'prediction'}, inplace=True)\n",
    "    return sample_submission[['id']].merge(merged_df[['id', 'prediction']], on='id', how='left')\n",
    "\n",
    "def main():\n",
    "    pd.set_option('display.max_rows', 200)\n",
    "    pd.set_option('display.max_columns', 200)\n",
    "    \n",
    "    X_train, Y_train, X_test = load_datasets()\n",
    "    predictions = train_and_predict(X_train, Y_train, X_test)\n",
    "    out_pd = prepare_submission(predictions, X_test)\n",
    "    sample_submission = merge_with_sample(out_pd)\n",
    "    sample_submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Prints the provided string.\")\n",
    "    parser.add_argument(\"-m\", \"--message\", type=str, help=\"Kaggle submission message.\")\n",
    "    args = parser.parse_args()\n",
    "    main()\n",
    "    if args.message:\n",
    "        execute_cmd(f'kaggle competitions submit -c solar-energy-production-forecasting -f submission.csv -m \"{args.message}\"')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML\n",
    "\n",
    "Now we added the AutoML we tried a few attempts ago into the script to compare. Here AutoML tried for a long time to obtain the best model possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import subprocess\n",
    "import argparse\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import autosklearn.regression\n",
    "\n",
    "def train_and_predict(X_train, y_train, X_test, model_type=\"regressor\"):\n",
    "    \"\"\"\n",
    "    Train and predict.\n",
    "\n",
    "    Parameters:\n",
    "    - X_train: Training features\n",
    "    - y_train: Training labels/targets\n",
    "    - X_test: Test features\n",
    "    - model_type (str): Either \"regressor\" for Decision Tree or \"automl\" for auto-sklearn.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: Predictions\n",
    "    \"\"\"\n",
    "    if model_type == \"regressor\":\n",
    "        model = DecisionTreeRegressor(random_state=1)\n",
    "    elif model_type == \"automl\":\n",
    "        model = autosklearn.regression.AutoSklearnRegressor(\n",
    "            time_left_for_this_task=600,\n",
    "            per_run_time_limit=60,\n",
    "            n_jobs=-1,\n",
    "            tmp_folder=\"/tmp/autosklearn_classification_example_tmp\",\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid model_type: {model_type}. Expected 'regressor' or 'classifier'.\")\n",
    "\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    print(\"Cross-validation scores:\", scores)\n",
    "    print(\"Average cross-validation score:\", scores.mean())\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    return pd.DataFrame(predictions)\n",
    "\n",
    "def validate(predicted_df, target_df):\n",
    "    train_targets = pd.read_parquet('data/A/train_targets.parquet')\n",
    "    \n",
    "    # Check if the number of samples in df and train_targets are the same\n",
    "    if len(predicted_df) != len(target_df):\n",
    "        raise ValueError(f\"Validate: Inconsistent number of samples: predicted_df has {len(predicted_df)} samples while target_df has {len(target_df)} samples.\")\n",
    "    \n",
    "    target_df.time = pd.to_datetime(target_df.time)\n",
    "    target_df.set_index('time', inplace=True)\n",
    "\n",
    "    # Set the 'time' column of df to match the index of target_df\n",
    "    predicted_df.time = pd.to_datetime(target_df.index)\n",
    "\n",
    "    # Compute RMSE\n",
    "    rmse = mean_squared_error(target_df, predicted_df, squared=False)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Initial Catboost & XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our first attempt to explore the possibility to use CatBoost and XGBoost. We added the two tools to the script and did a couple submissions to see their potential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import subprocess\n",
    "import argparse\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import autosklearn.regression\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "def train_and_predict(X_train, y_train, X_test, model_type=\"regressor\"):\n",
    "    \"\"\"\n",
    "    Train and predict.\n",
    "\n",
    "    Parameters:\n",
    "    - X_train: Training features\n",
    "    - y_train: Training labels/targets\n",
    "    - X_test: Test features\n",
    "    - model_type (str): Either \"regressor\" for Decision Tree or \"automl\" for auto-sklearn.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: Predictions\n",
    "    \"\"\"\n",
    "    if model_type == \"regressor\":\n",
    "        model = DecisionTreeRegressor(random_state=1)\n",
    "    elif model_type == \"automl\":\n",
    "        model = autosklearn.regression.AutoSklearnRegressor(\n",
    "            time_left_for_this_task=600,\n",
    "            per_run_time_limit=60,\n",
    "            n_jobs=-1,\n",
    "            tmp_folder=\"/tmp/autosklearn_classification_example_tmp\"\n",
    "        )\n",
    "    elif model_type == \"catboost\":\n",
    "        model = CatBoostRegressor()\n",
    "    elif model_type == 'xgboost':\n",
    "        model = XGBRegressor()\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid model_type: {model_type}. Expected 'regressor' or 'classifier'.\")\n",
    "\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    print(\"Cross-validation scores:\", scores)\n",
    "    print(\"Average cross-validation score:\", scores.mean())\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    try:\n",
    "        print(model.show_models())\n",
    "        print(model.leaderboard())\n",
    "        # print(\"MSE:\", mean_squared_error(y_test, predictions))\n",
    "        print(model.get_configuration_space(X_train, y_train))\n",
    "    except:\n",
    "        print(\"\")\n",
    "    return pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Catboost Update\n",
    "\n",
    "Catboost produced good results so we tried to perform some data engineering to improve it and update some of its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets():\n",
    "    X_test  = pd.read_parquet('data/prepared_datasets/non_cleaned/X_test.parquet')\n",
    "    X_train = pd.read_parquet('data/prepared_datasets/non_cleaned/X_train.parquet')\n",
    "    y_train = pd.read_parquet('data/prepared_datasets/non_cleaned/Y_train.parquet')\n",
    "    return X_train, y_train, X_test\n",
    "\n",
    "def train_and_predict(X_train, y_train, X_test, model_type=\"regressor\"):\n",
    "    \"\"\"\n",
    "    Train and predict.\n",
    "\n",
    "    Parameters:\n",
    "    - X_train: Training features\n",
    "    - y_train: Training labels/targets\n",
    "    - X_test: Test features\n",
    "    - model_type (str): Either \"regressor\" for Decision Tree or \"automl\" for auto-sklearn.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: Predictions\n",
    "    \"\"\"\n",
    "    if model_type == \"regressor\":\n",
    "        model = DecisionTreeRegressor(random_state=1)\n",
    "    elif model_type == \"automl\":\n",
    "        model = autosklearn.regression.AutoSklearnRegressor(\n",
    "            time_left_for_this_task=600,\n",
    "            per_run_time_limit=60,\n",
    "            n_jobs=-1,\n",
    "            tmp_folder=\"/tmp/autosklearn_classification_example_tmp\"\n",
    "        )\n",
    "    elif model_type == \"catboost\":\n",
    "        cat_features = ['location']\n",
    "        model = CatBoostRegressor(\n",
    "            cat_features=cat_features,\n",
    "            verbose=100\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked Catboost\n",
    "\n",
    "This attempt we checked the possibility of stacking the catboost models fitted to each location separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_A = None\n",
    "X_test_B = None\n",
    "X_test_C = None\n",
    "X_train_A = None\n",
    "X_train_B = None\n",
    "X_train_C = None\n",
    "y_train_A = None\n",
    "y_train_B = None\n",
    "y_train_C = None\n",
    "\n",
    "def load_datasets():\n",
    "    X_test  = pd.read_parquet('data/prepared_datasets/only_y_cleaned/X_test.parquet')\n",
    "    X_test_A = X_test[X_test['location'] == 'A']\n",
    "    X_test_B = X_test[X_test['location'] == 'B']\n",
    "    X_test_C = X_test[X_test['location'] == 'C']\n",
    "    X_train = pd.read_parquet('data/prepared_datasets/only_y_cleaned/X_train.parquet')\n",
    "    X_train_A = X_train[X_train['location'] == 'A']\n",
    "    X_train_B = X_train[X_train['location'] == 'B']\n",
    "    X_train_C = X_train[X_train['location'] == 'C']\n",
    "    y_train = pd.read_parquet('data/prepared_datasets/only_y_cleaned/Y_train.parquet')\n",
    "    y_train_A = y_train[y_train['location'] == 'A']\n",
    "    y_train_B = y_train[y_train['location'] == 'B']\n",
    "    y_train_C = y_train[y_train['location'] == 'C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    elif model_type == \"catboost\":\n",
    "        cat_features = ['location']\n",
    "        \n",
    "        model = CatBoostRegressor(\n",
    "            cat_features=cat_features,\n",
    "            verbose=100\n",
    "        )\n",
    "        model_B = CatBoostRegressor(\n",
    "            cat_features=cat_features,\n",
    "            verbose=100\n",
    "        )\n",
    "        \n",
    "        model_C = CatBoostRegressor(\n",
    "            cat_features=cat_features,\n",
    "            verbose=100\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    # print(\"Cross-validation scores:\", scores)\n",
    "    # print(\"Average cross-validation score:\", scores.mean())\n",
    "    \n",
    "    # model.fit(X_train, y_train)\n",
    "    # predictions = model.predict(X_test)\n",
    "    \n",
    "    model.fit(X_train_A, y_train_A)\n",
    "    predictions1 = model.predict(X_test_A)\n",
    "    \n",
    "    ts = TimeSeriesSplit(n_splits = 10)\n",
    "    cross_val_score(model, X_train_A, y_train_A, cv=ts, scoring='neg_mean_absolute_error')\n",
    "    \n",
    "    model_B.fit(X_train_B, y_train_B)\n",
    "    predictions2 = model_B.predict(X_test_B)\n",
    "        \n",
    "    model_C.fit(X_train_C, y_train_C)\n",
    "    predictions3 = model_C.predict(X_test_C)\n",
    "        \n",
    "    predictions = np.concatenate([predictions1, predictions2, predictions3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked A & B + C Catboost\n",
    "\n",
    "We also tried stacking A and he merged B and C location since A was much more different from the B and C datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    model_B.fit(pd.concat([X_train_B,X_train_C], axis=0), pd.concat([y_train_B, y_train_C],axis=0))\n",
    "    predictions2 = model_B.predict(pd.concat([X_test_B, X_test_C],axis=0))\n",
    "        \n",
    "    predictions = np.concatenate([predictions1, predictions2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Catboost: run average data in 1 large dataset but with loss_function=MAE\n",
    "Same model as before, but the average dataset was used.\n",
    "Hyperparamaters were choosen as default except for depth which was choosen to be 7 as it's a good average of the optune hyperparamaters.\n",
    "Submission are done as before, but we now cap the negative values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avg given\n",
    "def resample_df_hourly_keep_categorical(df, hourly_df, categorical_col_list):\n",
    "    \"\"\" \n",
    "    Hourly df must just be hourly index in the dataframe\n",
    "    \"\"\"\n",
    "    indices_to_keep = hourly_df.index\n",
    "    resampled_df = df.resample('1H').mean()\n",
    "    \n",
    "    for col in categorical_col_list:\n",
    "        resampled_df[col] = df.resample('1H')[col].agg(lambda x: x.mode()[0] if not x.isna().all() else np.nan)\n",
    "\n",
    "    resampled_df = resampled_df[resampled_df.index.isin(indices_to_keep)]\n",
    "    return resampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a pool of data\n",
    "train_pool = Pool(X_train, y_train, cat_features=[\"location\"])\n",
    "test_pool = Pool(X_test, cat_features=[\"location\"]) \n",
    "\n",
    "cat_feature = [\"location\"]\n",
    "\n",
    "#init model and fit it\n",
    "catboost_model = CatBoostRegressor(iterations=1000, depth=9, loss_function=\"MAE\")\n",
    "catboost_model.fit(train_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_model.get_feature_importance() #Gives a clear indication of which features the model decides to split on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions\n",
    "predictions = pd.DataFrame(catboost_model.predict(test_pool))\n",
    "print(predictions)\n",
    "predictions = predictions.clip(lower=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When using non-averaged dataset the model \n",
    "catboost_model.get_feature_importance()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "array([7.14454410e-01, 2.33463122e-01, 3.75397728e-01, 3.78254372e+00,\n",
    "       6.35562704e+00, 6.48771233e-01, 1.91280388e-04, 5.86727196e-01,\n",
    "       6.00286286e-01, 1.28453266e+00, 1.39580817e+01, 2.78000924e+00,\n",
    "       2.20047230e+00, 4.79723248e+01, 2.58961845e-02, 3.21505005e-05,\n",
    "       1.52380537e-01, 6.11855239e-06, 4.26232953e-03, 2.48798006e-02,\n",
    "       6.49045335e-03, 4.82516561e-01, 1.26288040e-01, 2.37755133e-01,\n",
    "       3.20094971e-01, 3.11507508e-01, 2.63411360e-04, 1.01815617e-02,\n",
    "       9.72448560e-01, 2.07196407e-01, 3.77712014e-02, 0.00000000e+00,\n",
    "       2.06891077e-03, 2.01484585e-01, 5.53600765e+00, 3.78416731e+00,\n",
    "       3.62264096e-01, 1.28156413e+00, 2.02655676e+00, 3.06863983e-01,\n",
    "       3.35129932e-01, 9.41018340e-01, 3.63968603e-01, 9.18614039e-04,\n",
    "       1.67854391e-01, 2.77279026e-01])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost - using location per location, but without / with an avg of the X_features\n",
    "Just simply running with the non averaged dataset per location. THe only changed code is below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load inn datasets\n",
    "X_test  = pd.read_parquet('data/prepared_datasets/avg/only_y_cleaned/X_test.parquet')\n",
    "X_train = pd.read_parquet('data/prepared_datasets/avg/only_y_cleaned/X_train.parquet')\n",
    "y_train = pd.read_parquet('data/prepared_datasets/avg/only_y_cleaned/Y_train.parquet')\n",
    "y_train_a = pd.read_parquet('data/prepared_datasets/avg/only_y_cleaned/Y_train_a.parquet')\n",
    "y_train_b = pd.read_parquet('data/prepared_datasets/avg/only_y_cleaned/Y_train_b.parquet')\n",
    "y_train_c = pd.read_parquet('data/prepared_datasets/avg/only_y_cleaned/Y_train_c.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final training and predictions\n",
    "X_train_a = X_train[X_train[\"location\"] == \"A\"].drop(\"location\", axis=1)\n",
    "X_train_b = X_train[X_train[\"location\"] == \"B\"].drop(\"location\", axis=1)\n",
    "X_train_c = X_train[X_train[\"location\"] == \"C\"].drop(\"location\", axis=1)\n",
    "\n",
    "X_test_a = X_test[X_test[\"location\"] == \"A\"].drop(\"location\", axis=1)\n",
    "X_test_b = X_test[X_test[\"location\"] == \"B\"].drop(\"location\", axis=1)\n",
    "X_test_c = X_test[X_test[\"location\"] == \"C\"].drop(\"location\", axis=1)\n",
    "          \n",
    "train_pool_a = Pool(X_train_a, y_train_a)\n",
    "train_pool_b = Pool(X_train_b, y_train_b)\n",
    "train_pool_c = Pool(X_train_c, y_train_c)\n",
    "\n",
    "\n",
    "test_pool_a = Pool(X_test_a) \n",
    "test_pool_b = Pool(X_test_b) \n",
    "test_pool_c = Pool(X_test_c) \n",
    "\n",
    "catboost_model_a = CatBoostRegressor(iterations=1000, loss_function=\"MAE\")\n",
    "catboost_model_b = CatBoostRegressor(iterations=1000, loss_function=\"MAE\")\n",
    "catboost_model_c = CatBoostRegressor(iterations=1000, loss_function=\"MAE\")\n",
    "\n",
    "catboost_model_a.fit(train_pool_a)\n",
    "catboost_model_b.fit(train_pool_b)\n",
    "catboost_model_c.fit(train_pool_c)\n",
    "\n",
    "\n",
    "pred_a = pd.DataFrame(catboost_model_a.predict(test_pool_a))\n",
    "pred_b = pd.DataFrame(catboost_model_b.predict(test_pool_b))\n",
    "pred_c = pd.DataFrame(catboost_model_c.predict(test_pool_c))\n",
    "\n",
    "predictions = pd.DataFrame(pd.concat([pred_a, pred_b, pred_c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gives a clear indication of which features the model decides to split on\n",
    "catboost_model_a.get_feature_importance() \n",
    "catboost_model_b.get_feature_importance()\n",
    "catboost_model_c.get_feature_importance()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which gives:\n",
    "\n",
    "[5.62286267e-01 5.10924360e-01 6.87543964e-01 7.09947835e+00\n",
    " 1.74363313e+01 9.85944986e-01 2.20760153e-04 5.58126247e-01\n",
    " 4.49025269e+00 8.30970146e-01 2.18527336e+01 9.53879922e+00\n",
    " 8.92806168e+00 0.00000000e+00 4.22781187e-02 3.11757422e-04\n",
    " 1.56871203e-01 1.95304107e-03 2.49194089e-02 1.57744874e-02\n",
    " 2.63958073e-02 3.28201853e-01 6.36442997e-01 2.39626670e-01\n",
    " 3.18970195e-01 8.77317441e-01 1.17008386e-03 1.39479027e-01\n",
    " 1.20973054e+00 1.72680735e-01 2.71240488e-02 0.00000000e+00\n",
    " 4.68738664e-03 2.42363183e-01 4.78004233e+00 8.46048186e+00\n",
    " 2.24121290e-02 9.89359658e-01 2.69676091e+00 2.51194813e+00\n",
    " 5.19759356e-01 1.55562505e+00 4.77258531e-01 4.11353283e-06\n",
    " 3.83763961e-02]\n",
    "[1.88022554e+00 1.15419262e+00 1.00922562e+00 7.48111890e+00\n",
    " 1.12733488e+01 2.72871859e+00 1.39014285e-02 1.88626231e+00\n",
    " 2.97976929e+00 1.34600324e+00 1.82486388e+01 7.59204454e+00\n",
    " 4.27088547e+00 0.00000000e+00 1.19532079e-02 1.10894864e-04\n",
    " 2.77594143e-01 5.77725208e-03 7.84931755e-03 1.27768791e-02\n",
    " 1.99097121e-02 1.06270592e+00 4.29635354e-01 5.97065686e-02\n",
    " 1.14551067e+00 9.21013435e-01 1.77340617e-05 2.49663816e-02\n",
    " 2.00966070e+00 9.08311203e-01 6.96748329e-02 0.00000000e+00\n",
    " 7.38318777e-04 3.68993942e-01 3.11252224e+00 1.83882500e+01\n",
    " 6.19693328e-02 3.92594191e+00 2.02225386e+00 4.13964400e-01\n",
    " 4.39549987e-01 1.26118441e+00 9.49111657e-01 0.00000000e+00\n",
    " 2.24010622e-01]\n",
    "[1.05183303e+00 5.47707872e-01 4.65832167e-01 9.62827924e+00\n",
    " 1.61346601e+01 5.59971031e-01 3.32030535e-06 1.83163516e+00\n",
    " 1.02105691e+00 9.94807280e-01 1.55418440e+01 1.42847250e+01\n",
    " 2.46223005e+00 0.00000000e+00 2.78951279e-01 2.64209261e-04\n",
    " 1.41965549e+00 8.09852309e-04 3.12673556e-02 8.59573696e-03\n",
    " 1.80568128e+00 8.51329761e-01 5.67418183e-01 1.13536266e-01\n",
    " 1.10745070e+00 5.78633083e-01 7.94598073e-17 2.64155735e-01\n",
    " 8.67329333e-01 9.04708781e-01 3.28500374e-01 0.00000000e+00\n",
    " 1.06570958e-01 2.69129368e-01 1.18569463e+00 1.38882300e+01\n",
    " 2.71306048e-01 6.33875372e+00 3.17699212e-01 7.24903457e-01\n",
    " 7.82524613e-01 1.10959525e+00 7.16590555e-01 1.79745716e-02\n",
    " 6.18155048e-01]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost but with logCosh loss function\n",
    "The logCosh loss func is like the MAE but derivable and stays convex, hopefully this gives us better scores\n",
    "All the code is the same, the non avg dataset is used and combined dataset is also used.\n",
    "No changed is EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load inn datasets\n",
    "X_test  = pd.read_parquet('data/prepared_datasets/only_y_cleaned/X_test.parquet')\n",
    "X_train = pd.read_parquet('data/prepared_datasets/only_y_cleaned/X_train.parquet')\n",
    "y_train = pd.read_parquet('data/prepared_datasets/only_y_cleaned/Y_train.parquet')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Create a pool of data\n",
    "train_pool = Pool(X_train, y_train, cat_features=[\"location\"])\n",
    "test_pool = Pool(X_test, cat_features=[\"location\"]) \n",
    "\n",
    "cat_feature = [\"location\"]\n",
    "\n",
    "#init model and fit it\n",
    "catboost_model = CatBoostRegressor(iterations=1000, depth=9, loss_function=\"LogCosh\")\n",
    "catboost_model.fit(train_pool)\n",
    "catboost:model.get_feature_importance()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "array([4.72592899e-01, 4.41204367e-01, 3.84270690e-01, 2.10027644e+00,\n",
    "       6.59232391e+00, 5.12073235e-01, 4.20970309e-04, 6.54575329e-01,\n",
    "       1.23954700e+00, 7.62895522e-01, 1.26428425e+01, 5.33669134e+00,\n",
    "       2.00509473e+00, 4.65390852e+01, 9.04155075e-03, 0.00000000e+00,\n",
    "       2.35266493e-01, 9.80361685e-05, 8.22728932e-03, 3.84898460e-02,\n",
    "       9.08180785e-02, 5.32835508e-01, 1.89160001e-01, 2.02757084e-01,\n",
    "       4.05391975e-01, 3.17490715e-01, 1.42871927e-06, 2.04189961e-01,\n",
    "       1.34250717e+00, 2.04729946e-01, 5.97507981e-02, 0.00000000e+00,\n",
    "       2.12119598e-03, 1.43597432e-01, 5.77122856e+00, 3.95295454e+00,\n",
    "       4.82876996e-02, 1.23904967e+00, 1.58323040e+00, 1.14037688e+00,\n",
    "       3.30905708e-01, 1.17824748e+00, 4.07264867e-01, 1.95389108e-03,\n",
    "       1.79484175e-01, 4.96647498e-01])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improved EDA by removing duplicates \n",
    "The changed code in the EDA is below\n",
    "- We tried both with only removing non-zero values and removing all duplicate values over another threshold.\n",
    "- The feature importances remained virtually unchanged between tries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates_over_threshold(df, threshold, col):\n",
    "    threshold = 4  # Set your threshold here\n",
    "\n",
    "    # Create a boolean mask to identify consecutive duplicates (non-zero values)\n",
    "    mask = df[col].ne(df[col].shift()).cumsum()\n",
    "\n",
    "    # Create a mask to identify rows that need to be kept (consecutive zeros, first in a group, or the first row of a group)\n",
    "    rank_within_group = df.groupby(mask)[col].rank(method='first')\n",
    "    keep_mask = (df[col] == 0) | (rank_within_group <= threshold - 1) | (mask != mask.shift())\n",
    "\n",
    "    # Filter the DataFrame based on the keep_mask\n",
    "    df_filtered = df[keep_mask]\n",
    "    return df_filtered\n",
    "\n",
    "train_all_filtered = remove_duplicates_over_threshold(train_all, 5, \"pv_measurement\")\n",
    "print(train_all[\"pv_measurement\"].info())\n",
    "print(train_all_filtered[\"pv_measurement\"].info())\n",
    "\n",
    "\n",
    "train_all = remove_duplicates_over_threshold(train_all, 5, \"pv_measurement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates_over_threshold_under_val(df, col, threshold, val):\n",
    "    # Define the threshold\n",
    "    threshold\n",
    "\n",
    "    # Create a boolean mask for values less than 1\n",
    "    mask = df[col] < val\n",
    "\n",
    "    # Use cumulative sum to identify consecutive groups of values less than 1\n",
    "    groups = (mask != mask.shift()).cumsum()\n",
    "\n",
    "    # Filter out groups that don't meet the threshold\n",
    "    valid_groups = groups[mask].value_counts() >= threshold\n",
    "    valid_mask = groups.map(valid_groups.get).fillna(False)\n",
    "\n",
    "    # Select rows that meet the criteria\n",
    "    filtered_df = df[~valid_mask]\n",
    "    return filtered_df\n",
    "\n",
    "train_all_filtered = remove_duplicates_over_threshold_under_val(train_all, \"pv_measurement\", 48, 1)\n",
    "print(train_all[\"pv_measurement\"].info())\n",
    "print(train_all_filtered[\"pv_measurement\"].info())\n",
    "\n",
    "train_all = remove_duplicates_over_threshold_under_val(train_all, \"pv_measurement\", 40, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_model.get_feature_importance()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "array([5.71567256e-01, 4.18943761e-01, 4.79040534e-01, 2.26873274e+00,\n",
    "       6.71437767e+00, 6.56502672e-01, 1.51028125e-03, 6.30578336e-01,\n",
    "       1.17645691e+00, 9.28116951e-01, 1.03661404e+01, 3.86780450e+00,\n",
    "       4.41558314e+00, 2.05461327e+01, 3.07241613e-02, 2.25237295e-07,\n",
    "       2.03511521e-01, 0.00000000e+00, 5.76017922e-03, 2.70136885e-02,\n",
    "       3.53194734e-03, 6.25759006e-01, 1.94652305e-01, 1.73253656e-01,\n",
    "       2.71579813e-01, 1.61276690e-01, 1.82465864e-04, 6.76767197e-02,\n",
    "       1.15612868e+00, 2.38809134e-01, 2.74421868e-02, 0.00000000e+00,\n",
    "       2.76030891e-03, 3.29892964e-01, 5.81940730e+00, 6.44946627e+00,\n",
    "       5.78456790e-02, 7.20871918e-01, 1.75597218e+00, 1.10972078e+00,\n",
    "       5.19280417e-01, 1.11229712e+00, 4.89601711e-01, 7.72833327e-04,\n",
    "       1.72535890e-01, 2.52307844e+01])\n",
    "\n",
    "It now weights more on the snow water feature"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cagboost - taking the avg and removing duplicates with a threshold of 9\n",
    "- No changed EDA or Model, only a change in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load inn datasets\n",
    "X_test  = pd.read_parquet('data/prepared_datasets/avg/no_duplicates/X_test.parquet')\n",
    "X_train = pd.read_parquet('data/prepared_datasets/avg/no_duplicates/X_train.parquet')\n",
    "y_train = pd.read_parquet('data/prepared_datasets/avg/no_duplicates/Y_train.parquet')\n",
    "y_train_a = pd.read_parquet('data/prepared_datasets/avg/no_duplicates/Y_train_a.parquet')\n",
    "y_train_b = pd.read_parquet('data/prepared_datasets/avg/no_duplicates/Y_train_b.parquet')\n",
    "y_train_c = pd.read_parquet('data/prepared_datasets/avg/no_duplicates/Y_train_c.parquet')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Create a pool of data\n",
    "train_pool = Pool(X_train, y_train, cat_features=[\"location\"])\n",
    "test_pool = Pool(X_test, cat_features=[\"location\"]) \n",
    "\n",
    "cat_feature = [\"location\"]\n",
    "\n",
    "#init model and fit it\n",
    "catboost_model = CatBoostRegressor(iterations=1000, depth=9, loss_function=\"LogCosh\", cat_features=cat_feature)\n",
    "catboost_model.fit(train_pool)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_model.get_feature_importance()\n",
    "\n",
    "array([7.32350783e-01, 2.85228912e-01, 4.64423211e-01, 2.65772002e+00,\n",
    "       6.79382843e+00, 5.63235254e-01, 1.58971861e-04, 7.14547511e-01,\n",
    "       1.54153096e+00, 1.61590896e+00, 9.87036516e+00, 5.90169639e+00,\n",
    "       3.48208012e+00, 2.43886989e+01, 2.96466324e-02, 1.70394143e-05,\n",
    "       1.84520658e-01, 2.86706848e-05, 6.65691294e-03, 2.53587352e-02,\n",
    "       3.65127523e-02, 3.81672809e-01, 3.91912356e-01, 2.56655871e-01,\n",
    "       6.73457813e-01, 1.88787672e-01, 5.97604128e-05, 2.95753886e-02,\n",
    "       3.69660461e-01, 2.83380598e-01, 4.04856707e-02, 0.00000000e+00,\n",
    "       3.54154150e-03, 4.53837486e-01, 2.75040585e+00, 5.29590786e+00,\n",
    "       3.31961327e-01, 1.20555840e+00, 1.59547574e+00, 1.09898773e+00,\n",
    "       5.04095718e-01, 1.31024818e+00, 4.68696145e-01, 6.25010978e-05,\n",
    "       1.17533127e-01, 2.29535251e+01])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempted to add time features \n",
    "Added time feature for day, month, year - this resulted in a much worse score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load inn datasets\n",
    "X_test  = pd.read_parquet('data/prepared_datasets/avg/time_features/X_test.parquet')\n",
    "X_train = pd.read_parquet('data/prepared_datasets/avg/time_features/X_train.parquet')\n",
    "y_train = pd.read_parquet('data/prepared_datasets/avg/time_features/Y_train.parquet')\n",
    "y_train_a = pd.read_parquet('data/prepared_datasets/avg/time_features/Y_train_a.parquet')\n",
    "y_train_b = pd.read_parquet('data/prepared_datasets/avg/time_features/Y_train_b.parquet')\n",
    "y_train_c = pd.read_parquet('data/prepared_datasets/avg/time_features/Y_train_c.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make the non-cyclical features \n",
    "train_all[\"hour\"] = train_all.index.hour\n",
    "train_all[\"day\"] = train_all.index.day\n",
    "train_all[\"month\"] = train_all.index.month\n",
    "train_all[\"year\"] = train_all.index.year\n",
    "\n",
    "X_test[\"hour\"] = X_test.index.hour\n",
    "X_test[\"day\"] = X_test.index.hour\n",
    "X_test[\"month\"] = X_test.index.hour\n",
    "X_test[\"year\"] = X_test.index.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a pool of data\n",
    "train_pool = Pool(X_train, y_train, cat_features=[\"location\"])\n",
    "test_pool = Pool(X_test, cat_features=[\"location\"]) \n",
    "\n",
    "cat_feature = [\"location\"]\n",
    "\n",
    "#init model and fit it\n",
    "catboost_model = CatBoostRegressor(iterations=1000, depth=9, loss_function=\"LogCosh\")\n",
    "catboost_model.fit(train_pool)\n",
    "catboost:model.get_feature_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array([5.84361316e-01, 4.17091513e-01, 2.96880145e-01, 2.43437044e+00,\n",
    "       4.32688271e+00, 5.62287811e-01, 1.06781780e-04, 6.55233426e-01,\n",
    "       1.77960798e+00, 5.68483469e-01, 1.25757987e+01, 3.35238284e+00,\n",
    "       4.24354725e+00, 2.70343617e+01, 5.76731375e-03, 1.55130847e-05,\n",
    "       2.43668225e-01, 2.87369588e-04, 9.47068259e-03, 1.70520459e-02,\n",
    "       1.12954553e-01, 4.31647511e-01, 2.51294488e-01, 4.38010946e-01,\n",
    "       2.62406292e-01, 2.90149046e-01, 3.17302370e-04, 2.71996969e-02,\n",
    "       1.73608779e+00, 2.56813887e-01, 2.91341776e-02, 0.00000000e+00,\n",
    "       3.76342692e-03, 2.19281392e-01, 1.29732337e+00, 6.03619154e+00,\n",
    "       2.32270574e-01, 9.61655907e-01, 9.59912491e-01, 6.93837093e-01,\n",
    "       5.34365778e-01, 7.48165307e-01, 5.07625357e-01, 6.63314403e-04,\n",
    "       1.24189301e-01, 2.03899539e+01, 1.55471300e+00, 6.08523329e-01,\n",
    "       1.06854582e+00, 1.11534606e+00])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking attempts of the best catboosts from here on!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacked the catboost pred of the avg non duplicates (theshold 10) and non-avg dataset with simple logcosh catboost\n",
    "- No changes in eda except for theshold function changed\n",
    "- New catboost models below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load inn datasets\n",
    "X_test  = pd.read_parquet('data/prepared_datasets/avg/no_duplicates/X_test.parquet')\n",
    "X_train_avg = pd.read_parquet('data/prepared_datasets/avg/no_duplicates/X_train.parquet')\n",
    "y_train_avg = pd.read_parquet('data/prepared_datasets/avg/no_duplicates/Y_train.parquet')\n",
    "y_train_a_avg = pd.read_parquet('data/prepared_datasets/avg/no_duplicates/Y_train_a.parquet')\n",
    "y_train_b_avg = pd.read_parquet('data/prepared_datasets/avg/no_duplicates/Y_train_b.parquet')\n",
    "y_train_c_avg = pd.read_parquet('data/prepared_datasets/avg/no_duplicates/Y_train_c.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load inn datasets\n",
    "X_test  = pd.read_parquet('data/prepared_datasets/only_y_cleaned/X_test.parquet')\n",
    "X_train_non_avg = pd.read_parquet('data/prepared_datasets/only_y_cleaned/X_train.parquet')\n",
    "y_train_non_avg = pd.read_parquet('data/prepared_datasets/only_y_cleaned/Y_train.parquet')\n",
    "y_train_a_non_avg = pd.read_parquet('data/prepared_datasets/only_y_cleaned/Y_train_a.parquet')\n",
    "y_train_b_non_avg = pd.read_parquet('data/prepared_datasets/only_y_cleaned/Y_train_b.parquet')\n",
    "y_train_c_non_avg = pd.read_parquet('data/prepared_datasets/only_y_cleaned/Y_train_c.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a pool of data\n",
    "train_pool_avg = Pool(X_train_avg, y_train_avg, cat_features=[\"location\"])\n",
    "test_pool_avg = Pool(X_test, cat_features=[\"location\"]) \n",
    "\n",
    "train_pool_non_avg = Pool(X_train_non_avg, y_train_non_avg, cat_features=[\"location\"])\n",
    "test_pool_non_avg = Pool(X_test, cat_features=[\"location\"]) \n",
    "\n",
    "#init models and fit them\n",
    "catboost_model_avg = CatBoostRegressor(iterations=1000, depth=9, loss_function=\"LogCosh\", verbose=100)\n",
    "catboost_model_avg.fit(train_pool_avg)\n",
    "\n",
    "catboost_model_non_avg = CatBoostRegressor(iterations=1000, depth=9, loss_function=\"LogCosh\", verbose=100)\n",
    "catboost_model_non_avg.fit(train_pool_non_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_avg = catboost_model_avg.predict(test_pool_avg)\n",
    "pred_non_avg = catboost_model_non_avg.predict(test_pool_non_avg)\n",
    "\n",
    "pred_stacked = pd.DataFrame((pred_avg + pred_non_avg) / 2)\n",
    "\n",
    "predictions = pred_stacked.clip(lower=0)\n",
    "\n",
    "def replace_under_0_2(x):\n",
    "    if x < 0.2:\n",
    "        return 0\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "predictions = pred_stacked.applymap(replace_under_0_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates_over_threshold(df, threshold, col):\n",
    "    threshold # Set your threshold here\n",
    "\n",
    "    # Create a boolean mask to identify consecutive duplicates (non-zero values)\n",
    "    mask = df[col].ne(df[col].shift()).cumsum()\n",
    "\n",
    "    # Create a mask to identify rows that need to be kept (consecutive zeros, first in a group, or the first row of a group)\n",
    "    rank_within_group = df.groupby(mask)[col].rank(method='first')\n",
    "    keep_mask = (df[col] == 0) | (rank_within_group <= threshold - 1) | (mask != mask.shift())\n",
    "\n",
    "    # Filter the DataFrame based on the keep_mask\n",
    "    df_filtered = df[keep_mask]\n",
    "    return df_filtered\n",
    "\n",
    "#train_all_filtered = remove_duplicates_over_threshold(train_all, 9, \"pv_measurement\")\n",
    "#print(train_all[\"pv_measurement\"].info())\n",
    "#print(train_all_filtered[\"pv_measurement\"].info())\n",
    "\n",
    "\n",
    "train_all = remove_duplicates_over_threshold(train_all, 10, \"pv_measurement\")\n",
    "\n",
    "#We then saved the new avg data to the datafolder with the same datcleaning as before"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attempting to stack with only summer data\n",
    "-all code the same except for added summer data for avg /non-avg case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The remaining data is the same as before.\n",
    "#This was done to the averaged dataset and the non-averaged dataset\n",
    "train_all_summer = train_all[(train_all.index.month >= 5) & (train_all.index.month <= 7) & (train_all.index.day >= 1) & (train_all.index.day <= 30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load inn datasets\n",
    "X_test  = pd.read_parquet('data/prepared_datasets/avg/no_duplicates/X_test.parquet')\n",
    "X_train_avg = pd.read_parquet('data/prepared_datasets/avg/no_duplicates/X_train.parquet')\n",
    "y_train_avg = pd.read_parquet('data/prepared_datasets/avg/no_duplicates/Y_train.parquet')\n",
    "y_train_a_avg = pd.read_parquet('data/prepared_datasets/avg/no_duplicates/Y_train_a.parquet')\n",
    "y_train_b_avg = pd.read_parquet('data/prepared_datasets/avg/no_duplicates/Y_train_b.parquet')\n",
    "y_train_c_avg = pd.read_parquet('data/prepared_datasets/avg/no_duplicates/Y_train_c.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load inn datasets\n",
    "X_test  = pd.read_parquet('data/prepared_datasets/only_y_cleaned/X_test.parquet')\n",
    "X_train_non_avg = pd.read_parquet('data/prepared_datasets/only_y_cleaned/X_train.parquet')\n",
    "y_train_non_avg = pd.read_parquet('data/prepared_datasets/only_y_cleaned/Y_train.parquet')\n",
    "y_train_a_non_avg = pd.read_parquet('data/prepared_datasets/only_y_cleaned/Y_train_a.parquet')\n",
    "y_train_b_non_avg = pd.read_parquet('data/prepared_datasets/only_y_cleaned/Y_train_b.parquet')\n",
    "y_train_c_non_avg = pd.read_parquet('data/prepared_datasets/only_y_cleaned/Y_train_c.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load inn datasets\n",
    "X_test  = pd.read_parquet('data/prepared_datasets/avg/summer/X_test.parquet')\n",
    "X_train_avg_summer = pd.read_parquet('data/prepared_datasets/avg/summer/X_train.parquet')\n",
    "y_train_avg_summer = pd.read_parquet('data/prepared_datasets/avg/summer/Y_train.parquet')\n",
    "y_train_a_avg_summer = pd.read_parquet('data/prepared_datasets/avg/summer/Y_train_a.parquet')\n",
    "y_train_b_avg_summer = pd.read_parquet('data/prepared_datasets/avg/summer/Y_train_b.parquet')\n",
    "y_train_c_avg_summer = pd.read_parquet('data/prepared_datasets/avg/summer/Y_train_c.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load inn datasets\n",
    "X_test  = pd.read_parquet('data/prepared_datasets/only_y_cleaned/X_test.parquet')\n",
    "X_train_non_avg_summer = pd.read_parquet('data/prepared_datasets/summer/X_train.parquet')\n",
    "y_train_non_avg_summer = pd.read_parquet('data/prepared_datasets/summer/Y_train.parquet')\n",
    "y_train_a_non_avg_summer = pd.read_parquet('data/prepared_datasets/summer/Y_train_a.parquet')\n",
    "y_train_b_non_avg_summer = pd.read_parquet('data/prepared_datasets/summer/Y_train_b.parquet')\n",
    "y_train_c_non_avg_summer = pd.read_parquet('data/prepared_datasets/summer/Y_train_c.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a pool of data\n",
    "train_pool_avg = Pool(X_train_avg, y_train_avg, cat_features=[\"location\"])\n",
    "test_pool_avg = Pool(X_test, cat_features=[\"location\"]) \n",
    "\n",
    "train_pool_non_avg = Pool(X_train_non_avg, y_train_non_avg, cat_features=[\"location\"])\n",
    "test_pool_non_avg = Pool(X_test, cat_features=[\"location\"]) \n",
    "\n",
    "#init models and fit them\n",
    "catboost_model_avg = CatBoostRegressor(iterations=1000, depth=9, loss_function=\"LogCosh\", verbose=100)\n",
    "catboost_model_avg.fit(train_pool_avg)\n",
    "\n",
    "catboost_model_non_avg = CatBoostRegressor(iterations=1000, depth=9, loss_function=\"LogCosh\", verbose=100)\n",
    "catboost_model_non_avg.fit(train_pool_non_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a pool of data\n",
    "train_pool_avg_summer = Pool(X_train_avg_summer, y_train_avg_summer, cat_features=[\"location\"])\n",
    "test_pool_avg_summer = Pool(X_test, cat_features=[\"location\"]) \n",
    "\n",
    "train_pool_non_avg_summer = Pool(X_train_non_avg_summer, y_train_non_avg_summer, cat_features=[\"location\"])\n",
    "test_pool_non_avg_summer = Pool(X_test, cat_features=[\"location\"]) \n",
    "\n",
    "#init models and fit them\n",
    "catboost_model_avg_summer = CatBoostRegressor(iterations=1000, depth=9, loss_function=\"LogCosh\", verbose=100)\n",
    "catboost_model_avg_summer.fit(train_pool_avg_summer)\n",
    "\n",
    "catboost_model_non_avg_summer = CatBoostRegressor(iterations=1000, depth=9, loss_function=\"LogCosh\", verbose=100)\n",
    "catboost_model_non_avg_summer.fit(train_pool_non_avg_summer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions for summer\n",
    "pred_avg_summer = catboost_model_avg_summer.predict(test_pool_avg_summer)\n",
    "pred_non_avg_summer = catboost_model_non_avg_summer.predict(test_pool_non_avg_summer)\n",
    "\n",
    "pred_stacked_summer = (pred_avg_summer + pred_non_avg_summer) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions for non-summer\n",
    "pred_avg = catboost_model_avg.predict(test_pool_avg)\n",
    "pred_non_avg = catboost_model_non_avg.predict(test_pool_non_avg)\n",
    "\n",
    "pred_stacked = (pred_avg + pred_non_avg) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tot_stacked = pd.DataFrame(0.65*pred_stacked + 0.35*pred_stacked_summer)\n",
    "\n",
    "predictions = pred_tot_stacked.clip(lower=0)\n",
    "\n",
    "def replace_under_0_2(x):\n",
    "    if x < 0.2:\n",
    "        return 0\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "predictions = pred_tot_stacked.applymap(replace_under_0_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attempting to submit only data for summer\n",
    "-all code same as before. however only the stack containing the summer data was submitted. This got a score of 150, which indicates we maybe should stack them more similarly "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adding validation of different summer to the stack\n",
    "Simply adding avg non duplicates data with optuna tuning for different summers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_split(df):\n",
    "    dates_2 = (df.index >= '2023-04-01') & (df.index <= '2023-04-15')\n",
    "    dates_1 = (df.index >= '2020-05-01') & (df.index <= '2020-08-01')\n",
    "\n",
    "    test_set = df[dates_1 | dates_2]\n",
    "\n",
    "    training_set = df[~(dates_1 | dates_2)]\n",
    "\n",
    "    X_train = training_set.drop(\"pv_measurement\", axis=1)\n",
    "    y_train = training_set['pv_measurement']\n",
    "\n",
    "    X_test = test_set.drop(\"pv_measurement\", axis=1)\n",
    "    y_test = test_set['pv_measurement'] \n",
    "\n",
    "    \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_trainnew_a, X_test_new_a, y_train_new_a, y_test_a = test_train_split(pd.concat([X_train[X_train[\"location\"] == \"A\"].drop(\"location\", axis=1), y_train_a], axis=1))\n",
    "X_train_new_b, X_test_new_b, y_train_new_b, y_test_b = test_train_split(pd.concat([X_train[X_train[\"location\"] == \"B\"].drop(\"location\", axis=1), y_train_b], axis=1))\n",
    "X_train_new_c, X_test_new_c, y_train_new_c, y_test_c = test_train_split(pd.concat([X_train[X_train[\"location\"] == \"C\"].drop(\"location\", axis=1), y_train_c], axis=1))\n",
    "\n",
    "X_train_loc_a, X_test_loc_a, y_train_loc_a, y_test_a = test_train_split(pd.concat([X_train[X_train[\"location\"] == \"A\"], y_train_a], axis=1))\n",
    "X_train_loc_b, X_test_loc_b, y_train_loc_b, y_test_b = test_train_split(pd.concat([X_train[X_train[\"location\"] == \"B\"], y_train_b], axis=1))\n",
    "X_train_loc_c, X_test_loc_c, y_train_loc_c, y_test_c = test_train_split(pd.concat([X_train[X_train[\"location\"] == \"C\"], y_train_c], axis=1))\n",
    "\n",
    "\n",
    "X_train_new = pd.concat([X_train_loc_a, X_train_loc_b, X_train_loc_c])\n",
    "X_test_new = pd.concat([X_test_loc_a, X_test_loc_b, X_test_loc_c])\n",
    "y_train_new = pd.concat([y_train_loc_a, y_train_loc_b, y_train_loc_c])\n",
    "y_test = pd.concat([y_test_a, y_test_b, y_test_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_split(df):\n",
    "    dates_2 = (df.index >= '2023-04-01') & (df.index <= '2023-04-15')\n",
    "    dates_1 = (df.index >= '2021-05-01') & (df.index <= '2021-08-01')\n",
    "\n",
    "    test_set = df[dates_1 | dates_2]\n",
    "\n",
    "    training_set = df[~(dates_1 | dates_2)]\n",
    "\n",
    "    X_train = training_set.drop(\"pv_measurement\", axis=1)\n",
    "    y_train = training_set['pv_measurement']\n",
    "\n",
    "    X_test = test_set.drop(\"pv_measurement\", axis=1)\n",
    "    y_test = test_set['pv_measurement'] \n",
    "\n",
    "    \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_trainnew_a, X_test_new_a, y_train_new_a, y_test_a = test_train_split(pd.concat([X_train[X_train[\"location\"] == \"A\"].drop(\"location\", axis=1), y_train_a], axis=1))\n",
    "X_train_new_b, X_test_new_b, y_train_new_b, y_test_b = test_train_split(pd.concat([X_train[X_train[\"location\"] == \"B\"].drop(\"location\", axis=1), y_train_b], axis=1))\n",
    "X_train_new_c, X_test_new_c, y_train_new_c, y_test_c = test_train_split(pd.concat([X_train[X_train[\"location\"] == \"C\"].drop(\"location\", axis=1), y_train_c], axis=1))\n",
    "\n",
    "X_train_loc_a, X_test_loc_a, y_train_loc_a, y_test_a = test_train_split(pd.concat([X_train[X_train[\"location\"] == \"A\"], y_train_a], axis=1))\n",
    "X_train_loc_b, X_test_loc_b, y_train_loc_b, y_test_b = test_train_split(pd.concat([X_train[X_train[\"location\"] == \"B\"], y_train_b], axis=1))\n",
    "X_train_loc_c, X_test_loc_c, y_train_loc_c, y_test_c = test_train_split(pd.concat([X_train[X_train[\"location\"] == \"C\"], y_train_c], axis=1))\n",
    "\n",
    "\n",
    "X_train_new = pd.concat([X_train_loc_a, X_train_loc_b, X_train_loc_c])\n",
    "X_test_new = pd.concat([X_test_loc_a, X_test_loc_b, X_test_loc_c])\n",
    "y_train_new = pd.concat([y_train_loc_a, y_train_loc_b, y_train_loc_c])\n",
    "y_test = pd.concat([y_test_a, y_test_b, y_test_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, X_train, y_train):\n",
    "    params = {\n",
    "        \"iterations\": trial.suggest_int(\"iterations\", 300, 4000),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 1, 13),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 100),\n",
    "        \"l2_leaf_reg\": trial.suggest_int(\"l2_leaf_reg\", 2, 10),\n",
    "        \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0.3, 1.0),\n",
    "        \"random_strength\": trial.suggest_float(\"random_strength\", 0.3, 1.0),\n",
    "        \"border_count\": trial.suggest_int(\"border_count\", 1, 1000),\n",
    "        \"rsm\": trial.suggest_float(\"rsm\", 0.05, 1),\n",
    "        \"loss_function\": \"LogCosh\"\n",
    "    }\n",
    "\n",
    "    catboost_model_val = CatBoostRegressor(**params, verbose=200)\n",
    "    catboost_model_val.fit(train_pool)\n",
    "    pred = pd.DataFrame(catboost_model_val.predict(test_pool))\n",
    "    MAE = mean_absolute_error(y_test, pred)\n",
    "\n",
    "    return MAE\n",
    "    \n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_new, y_train_new), n_trials=70)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Both were validated for and averaged between each other then added to the previous stack, the best result was found by not including the summer data.\n",
    "We then tested adding a training of location per location to the stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create training location per location with prev found hyperparamaters focusing on 2020 summer\n",
    "params_a = {'iterations': 2511, 'learning_rate': 0.013387708538234228, 'depth': 9, 'min_data_in_leaf': 37, 'l2_leaf_reg': 9, 'bagging_temperature': 0.6037942407543951, 'random_strength': 0.7203046909719719, 'border_count': 792, 'rsm': 0.5142593972884377, \"loss_function\": \"LogCosh\"}\n",
    "params_b = {'iterations': 1647, 'learning_rate': 0.008285667949530987, 'depth': 2, 'min_data_in_leaf': 7, 'l2_leaf_reg': 6, 'bagging_temperature': 0.638344903820208, 'random_strength': 0.9388444992830671, 'border_count': 434, 'rsm': 0.8347735297026142, \"loss_function\": \"LogCosh\"}\n",
    "params_c = {'iterations': 2216, 'learning_rate': 0.02932152249119453, 'depth': 10, 'min_data_in_leaf': 21, 'l2_leaf_reg': 2, 'bagging_temperature': 0.8784102456931138, 'random_strength': 0.6901129919784297, 'border_count': 119, 'rsm': 0.8571604856673344, \"loss_function\": \"LogCosh\"}\n",
    "\n",
    "X_train_a = X_train_non_avg[X_train_non_avg[\"location\"] == \"A\"].drop(\"location\", axis=1)\n",
    "X_train_b = X_train_non_avg[X_train_non_avg[\"location\"] == \"B\"].drop(\"location\", axis=1)\n",
    "X_train_c = X_train_non_avg[X_train_non_avg[\"location\"] == \"C\"].drop(\"location\", axis=1)\n",
    "\n",
    "X_test_a = X_test[X_test[\"location\"] == \"A\"].drop(\"location\", axis=1)\n",
    "X_test_b = X_test[X_test[\"location\"] == \"B\"].drop(\"location\", axis=1)\n",
    "X_test_c = X_test[X_test[\"location\"] == \"C\"].drop(\"location\", axis=1)\n",
    "          \n",
    "train_pool_a = Pool(X_train_a, y_train_a_non_avg)\n",
    "train_pool_b = Pool(X_train_b, y_train_b_non_avg)\n",
    "train_pool_c = Pool(X_train_c, y_train_c_non_avg)\n",
    "\n",
    "\n",
    "test_pool_a = Pool(X_test_a) \n",
    "test_pool_b = Pool(X_test_b) \n",
    "test_pool_c = Pool(X_test_c) \n",
    "\n",
    "catboost_model_a = CatBoostRegressor(**params_a)\n",
    "catboost_model_b = CatBoostRegressor(**params_b)\n",
    "catboost_model_c = CatBoostRegressor(**params_c)\n",
    "\n",
    "catboost_model_a.fit(train_pool_a)\n",
    "catboost_model_b.fit(train_pool_b)\n",
    "catboost_model_c.fit(train_pool_c)\n",
    "\n",
    "\n",
    "pred_a = catboost_model_a.predict(test_pool_a)\n",
    "pred_b = catboost_model_b.predict(test_pool_b)\n",
    "pred_c = catboost_model_c.predict(test_pool_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_a = catboost_model_a.predict(test_pool_a)\n",
    "pred_b = catboost_model_b.predict(test_pool_b)\n",
    "pred_c = catboost_model_c.predict(test_pool_c)\n",
    "pred_non_avg_per_location = np.concatenate((pred_a, pred_b, pred_c))\n",
    "\n",
    "pred_non_avg_per_location[pred_non_avg_per_location < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tot_stacked = pd.DataFrame((pred_stacked + pred_non_avg_per_location)/2)\n",
    "\n",
    "predictions = pred_tot_stacked.clip(lower=0)\n",
    "\n",
    "def replace_under_0_2(x):\n",
    "    if x < 0.2:\n",
    "        return 0\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "predictions = pred_tot_stacked.applymap(replace_under_0_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We also tested using location per location without avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_avg_a = {'iterations': 2511, 'learning_rate': 0.013387708538234228, 'depth': 9, 'min_data_in_leaf': 37, 'l2_leaf_reg': 9, 'bagging_temperature': 0.6037942407543951, 'random_strength': 0.7203046909719719, 'border_count': 792, 'rsm': 0.5142593972884377, \"loss_function\": \"LogCosh\"}\n",
    "params_avg_b = {'iterations': 1647, 'learning_rate': 0.008285667949530987, 'depth': 2, 'min_data_in_leaf': 7, 'l2_leaf_reg': 6, 'bagging_temperature': 0.638344903820208, 'random_strength': 0.9388444992830671, 'border_count': 434, 'rsm': 0.8347735297026142, \"loss_function\": \"LogCosh\"}\n",
    "params_avg_c = {'iterations': 2216, 'learning_rate': 0.02932152249119453, 'depth': 10, 'min_data_in_leaf': 21, 'l2_leaf_reg': 2, 'bagging_temperature': 0.8784102456931138, 'random_strength': 0.6901129919784297, 'border_count': 119, 'rsm': 0.8571604856673344, \"loss_function\": \"LogCosh\"}\n",
    "\n",
    "X_train_avg_a = X_train_avg[X_train_avg[\"location\"] == \"A\"].drop(\"location\", axis=1)\n",
    "X_train_avg_b = X_train_avg[X_train_avg[\"location\"] == \"B\"].drop(\"location\", axis=1)\n",
    "X_train_avg_c = X_train_avg[X_train_avg[\"location\"] == \"C\"].drop(\"location\", axis=1)\n",
    "\n",
    "X_test_a = X_test[X_test[\"location\"] == \"A\"].drop(\"location\", axis=1)\n",
    "X_test_b = X_test[X_test[\"location\"] == \"B\"].drop(\"location\", axis=1)\n",
    "X_test_c = X_test[X_test[\"location\"] == \"C\"].drop(\"location\", axis=1)\n",
    "          \n",
    "train_pool_avg_a = Pool(X_train_avg_a, y_train_a_avg)\n",
    "train_pool_avg_b = Pool(X_train_avg_b, y_train_b_avg)\n",
    "train_pool_avg_c = Pool(X_train_avg_c, y_train_c_avg)\n",
    "\n",
    "\n",
    "test_pool_a = Pool(X_test_a) \n",
    "test_pool_b = Pool(X_test_b) \n",
    "test_pool_c = Pool(X_test_c) \n",
    "\n",
    "catboost_model_avg_a = CatBoostRegressor(**params_avg_a, verbose=400)\n",
    "catboost_model_avg_b = CatBoostRegressor(**params_avg_b, verbose=400)\n",
    "catboost_model_avg_c = CatBoostRegressor(**params_avg_c, verbose=400)\n",
    "\n",
    "catboost_model_avg_a.fit(train_pool_a)\n",
    "catboost_model_avg_b.fit(train_pool_b)\n",
    "catboost_model_avg_c.fit(train_pool_c)\n",
    "\n",
    "pred_avg_a = catboost_model_avg_a.predict(test_pool_a)\n",
    "pred_avg_b = catboost_model_avg_b.predict(test_pool_b)\n",
    "pred_avg_c = catboost_model_avg_c.predict(test_pool_c)\n",
    "\n",
    "pred_avg_per_location = np.concatenate((pred_avg_a, pred_avg_b, pred_avg_c))\n",
    "\n",
    "pred_avg_per_location[pred_avg_per_location < 0] = 0\n",
    "\n",
    "pred_tot_stacked = pd.DataFrame((pred_stacked + pred_non_avg_per_location + pred_avg_per_location)/3)\n",
    "\n",
    "predictions = pred_tot_stacked.clip(lower=0)\n",
    "\n",
    "def replace_under_0_2(x):\n",
    "    if x < 0.2:\n",
    "        return 0\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "predictions = pred_tot_stacked.applymap(replace_under_0_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then added a new avg dataset, where the low duplicated values (typically where there is snow covering the sensor) was removed.\n",
    "This was then fitted on a catboost model and added to the stack. THe code to create the new data is given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_duplicates_over_threshold_under_val(df, col, threshold, val):\n",
    "    # Define the threshold\n",
    "    threshold\n",
    "\n",
    "    # Create a boolean mask for values less than 1\n",
    "    mask = df[col] == 0\n",
    "\n",
    "    # Use cumulative sum to identify consecutive groups of values less than 1\n",
    "    groups = (mask != mask.shift()).cumsum()\n",
    "\n",
    "    # Filter out groups that don't meet the threshold\n",
    "    valid_groups = groups[mask].value_counts() >= threshold\n",
    "    valid_mask = groups.map(valid_groups.get).fillna(False)\n",
    "\n",
    "    # Select rows that meet the criteria\n",
    "    filtered_df = df[~valid_mask]\n",
    "    return filtered_df\n",
    "\n",
    "train_all_filtered = remove_duplicates_over_threshold_under_val(train_all, \"pv_measurement\", 48, 1)\n",
    "print(train_all[\"pv_measurement\"].info())\n",
    "print(train_all_filtered[\"pv_measurement\"].info())\n",
    "\n",
    "train_all = remove_duplicates_over_threshold_under_val(train_all, \"pv_measurement\", 40, 1)\n",
    "\n",
    "#The new training data is then saved to a prepared data folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New catboost model with the removed lows\n",
    "train_pool_avg_no_lows = Pool(X_train_avg_no_lows, y_train_avg_no_lows, cat_features=[\"location\"])\n",
    "test_pool = Pool(X_test, cat_features=[\"location\"]) \n",
    "\n",
    "catboost_model_avg_no_lows = CatBoostRegressor(iterations=1000, depth=9, loss_function=\"LogCosh\", verbose=100)\n",
    "catboost_model_avg_no_lows.fit(train_pool_avg_no_lows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tot_stacked = pd.DataFrame((pred_avg + pred_non_avg + pred_non_avg_per_location + pred_avg_no_lows)/4)\n",
    "\n",
    "predictions = pred_tot_stacked.clip(lower=0)\n",
    "\n",
    "def replace_under_0_2(x):\n",
    "    if x < 0.2:\n",
    "        return 0\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "predictions = pred_tot_stacked.applymap(replace_under_0_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then tried a new stack with the summer data and the above stack, this resulted in worse scores.\n",
    "After we tried the same stack as above, but with default hyperparamaters for catboost but trained location per location - resulted in worse scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autogluon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is one Autogluon notebook we attempted alongside Catboost, it produced promising results but the results where not consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor\n",
    "from IPython.display import display\n",
    "from functools import reduce\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_df(dataframes):\n",
    "    \"\"\"\n",
    "    Merges multiple pandas DataFrames on their index.\n",
    "\n",
    "    Parameters:\n",
    "    dataframes (list of pandas.DataFrame): The list of DataFrames to merge.\n",
    "    how (str): Type of merge to perform:\n",
    "        - 'left': use only keys from left frame (SQL: left outer join)\n",
    "        - 'right': use only keys from right frame (SQL: right outer join)\n",
    "        - 'outer': use union of keys from both frames (SQL: full outer join)\n",
    "        - 'inner': use intersection of keys from both frames (SQL: inner join)\n",
    "    remove_duplicates (bool): Whether to remove duplicated rows after merging.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: The merged DataFrame.\n",
    "    \"\"\"\n",
    "    # Start with the first DataFrame in the list\n",
    "    merged_df = dataframes[0]\n",
    "\n",
    "    # Iteratively merge each DataFrame in the list\n",
    "    for df in dataframes[1:]:\n",
    "        merged_df = merged_df.join(df, how='left')\n",
    "\n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_df(dataframes, axis='index'):\n",
    "    # Identify common columns by intersecting all DataFrame columns\n",
    "    common_columns = reduce(lambda x, y: x.intersection(y.columns), dataframes, dataframes[0].columns)\n",
    "\n",
    "    # Reindex all DataFrames to these common columns\n",
    "    dfs_common = [df[common_columns] for df in dataframes]\n",
    "\n",
    "    # Concatenate the reindexed DataFrames\n",
    "    return pd.concat(dfs_common, axis=axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_parquet(filepath):\n",
    "    try:\n",
    "        # Read the file\n",
    "        df = pd.read_parquet(filepath)\n",
    "        \n",
    "        columns = ['date_forecast', 'time']\n",
    "\n",
    "        for column in columns:\n",
    "            if column in df.columns:\n",
    "                df.set_index(column, inplace=True)\n",
    "                break\n",
    "        else:\n",
    "            print(\"Datetime column not found\")\n",
    "            \n",
    "        # Get the location from the filepath\n",
    "        location = os.path.basename(os.path.dirname(filepath))\n",
    "        data_type = os.path.basename(filepath).rsplit('.parquet')[0]\n",
    "        \n",
    "        # Create a MultiIndex\n",
    "        df.index = pd.MultiIndex.from_product([[data_type], [location], df.index], names=['Data_Type', 'Location', 'Time'])\n",
    "        \n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_time_delta(df):\n",
    "\n",
    "    data_sorted = df.sort_index()\n",
    "    time_deltas = data_sorted.index.to_series().diff().dropna()\n",
    "    non_zero_deltas = time_deltas[time_deltas != pd.Timedelta(0)]\n",
    "    min_time_delta = non_zero_deltas.min().total_seconds()\n",
    "\n",
    "    if min_time_delta < 3600:\n",
    "        # Convert to minutes\n",
    "        return f\"{min_time_delta // 60:.0f}T\"\n",
    "    else:\n",
    "        # Convert to hours\n",
    "        return f\"{min_time_delta // 3600:.0f}H\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataframes = []\n",
    "directory = '/home/andres/ml/data/'\n",
    "filepaths = glob.glob(os.path.join(directory, '**', '*.parquet'), recursive=True)\n",
    "\n",
    "for filepath in filepaths:\n",
    "    df = read_parquet(filepath)\n",
    "    dataframes.append(df)\n",
    "data = pd.concat(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_observed = data.xs('X_train_observed')\n",
    "X_train_estimated = data.xs('X_train_estimated')\n",
    "X_train = pd.concat([X_train_observed, X_train_estimated])\n",
    "Y_train = data.xs('train_targets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(data):\n",
    "\n",
    "    interpolation_methods = {\n",
    "        'absolute_humidity_2m:gm3': 'index',\n",
    "        'air_density_2m:kgm3': 'index',\n",
    "        'ceiling_height_agl:m': 'index',\n",
    "        'clear_sky_energy_1h:J': 'cubic',\n",
    "        'clear_sky_rad:W': 'cubic',\n",
    "        'cloud_base_agl:m': 'pchip',\n",
    "        'dew_or_rime:idx': 'nearest',\n",
    "        'dew_point_2m:K': 'linear',\n",
    "        'diffuse_rad:W': 'cubic',\n",
    "        'diffuse_rad_1h:J': 'cubic',\n",
    "        'direct_rad:W': 'cubic',\n",
    "        'direct_rad_1h:J': 'cubic',\n",
    "        'effective_cloud_cover:p': 'index',\n",
    "        'elevation:m': 'pad',\n",
    "        'fresh_snow_12h:cm': 'zero',\n",
    "        'fresh_snow_1h:cm': 'zero',\n",
    "        'fresh_snow_24h:cm': 'zero',\n",
    "        'fresh_snow_3h:cm': 'zero',\n",
    "        'fresh_snow_6h:cm': 'zero',\n",
    "        'is_day:idx': 'pad',\n",
    "        'is_in_shadow:idx': 'pad',\n",
    "        'msl_pressure:hPa': 'time',\n",
    "        'precip_5min:mm': 'index',\n",
    "        'precip_type_5min:idx': 'nearest',\n",
    "        'pressure_100m:hPa': 'index',\n",
    "        'pressure_50m:hPa': 'index',\n",
    "        'prob_rime:p': 'index',\n",
    "        'rain_water:kgm2': 'index',\n",
    "        'relative_humidity_1000hPa:p': 'index',\n",
    "        'sfc_pressure:hPa': 'time',\n",
    "        'snow_density:kgm3': 'zero',\n",
    "        'snow_depth:cm': 'nearest',\n",
    "        'snow_drift:idx': 'pad',\n",
    "        'snow_melt_10min:mm': 'index',\n",
    "        'snow_water:kgm2': 'index',\n",
    "        'sun_azimuth:d': 'cubic',\n",
    "        'sun_elevation:d': 'cubic',\n",
    "        'super_cooled_liquid_water:kgm2': 'index',\n",
    "        't_1000hPa:K': 'index',\n",
    "        'total_cloud_cover:p': 'index',\n",
    "        'visibility:m': 'index',\n",
    "        'wind_speed_10m:ms': 'index',\n",
    "        'wind_speed_u_10m:ms': 'index',\n",
    "        'wind_speed_v_10m:ms': 'index',\n",
    "        'wind_speed_w_1000hPa:ms': 'index',\n",
    "        'pv_measurement':'index'\n",
    "    }\n",
    "    for column in data.columns:\n",
    "        data[column].interpolate(method=interpolation_methods.get(column, 'linear'), inplace=True)\n",
    "        if data[column].isna().any():\n",
    "            print(column + ' has NaN, replacing NaN with 0.')\n",
    "            data[column] = data[column].fillna(0)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_dfs = []\n",
    "for index_combination, sub_df in X_train.groupby(level='Location'):\n",
    "    sub_df = sub_df.reset_index(level='Location').resample('15T').asfreq(fill_value=None).drop(['pv_measurement','date_calc'], axis=1)\n",
    "    Y_train = Y_train.pv_measurement.reset_index(level='Location')\n",
    "    interpolate(Y_train)\n",
    "    Y_train.set_index('Location', inplace=True, append=True)\n",
    "    Y_train = Y_train.swaplevel()\n",
    "    train_data = merge_df([interpolate(sub_df),Y_train])\n",
    "    train_data['Location'] = index_combination\n",
    "    train_data.set_index('Location', inplace=True, append=True)\n",
    "    train_data = train_data.swaplevel()\n",
    "    sub_dfs.append(train_data)\n",
    "df = pd.concat(sub_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "df['Time'] = df['Time'].astype('datetime64[ns]')\n",
    "train_data = TimeSeriesDataFrame.from_data_frame(\n",
    "    df,\n",
    "    id_column=\"Location\",\n",
    "    timestamp_column=\"Time\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('/home/andres/ml/data/test.csv', index_col=['location', 'time'], parse_dates=['time'])\n",
    "sub_df = test.loc['A']\n",
    "test = sub_df\n",
    "num_predictions = test.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data_s, test_data_s) = train_data.train_test_split(prediction_length=num_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = read_parquet('/home/andres/ml/data/A/X_test_estimated.parquet',  'date_forecast','A')\n",
    "freq = get_min_time_delta(X_pred)\n",
    "X_pred = X_pred.resample(freq).asfreq(fill_value=None)\n",
    "interpolate(X_pred)\n",
    "X_pred['timestamp'] = X_pred.index.astype('datetime64[ns]')\n",
    "print(X_pred['timestamp'])\n",
    "X_pred['location'] = 'A'\n",
    "X_pred = TimeSeriesDataFrame.from_data_frame(\n",
    "    X_pred,\n",
    "    id_column=\"location\",\n",
    "    timestamp_column=\"timestamp\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = TimeSeriesPredictor(\n",
    "    prediction_length=num_predictions,\n",
    "    path=\"autogluon\",\n",
    "    target=\"pv_measurement\",\n",
    "    eval_metric=\"MSE\",\n",
    ")\n",
    "\n",
    "predictor.fit(\n",
    "    train_data_s,\n",
    "    presets=\"fast_training\",\n",
    "    time_limit=600,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(predictor.leaderboard(test_data_s, silent=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.evaluate(test_data_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictor.predict(train_data, known_covariates=X_pred)\n",
    "print(predictions.info())"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m112"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
